{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb68c3ee",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"bd6d5a06\" -->\n",
    "# Table des matières\n",
    "1. [Lecture et préparation des données](#lecture-et-préparation-des-données)\n",
    "1. [Entraînement d'un classificateur de type forêt aléatoire](#entraînement-dun-classificateur-de-type-forêt-aléatoire)\n",
    "1. [Affichage des statistiques de classification](#affichage-des-statistiques-de-classification)\n",
    "1. [Identification des variables les plus importantes pour diagnostiquer le diabète](#identification-des-variables-les-plus-importantes-pour-diagnostiquer-le-diabète)\n",
    "\n",
    "# Attention!\n",
    "Ne lancez pas l'exécution automatique du notebook en entier en cliquant sur le bouton **Tout exécuter**. L'exécution serait interrompue, car certaines cellules exigent une entrée de votre part!\n",
    "\n",
    "Il faut simplement exécuter le notebook, une cellule à la fois, et entrer quelques lignes de code lorsque demandées. Il est inutile de sauter ces cellules pour aller aux suivantes car celles-ci ont justement besoin de votre input!\n",
    "\n",
    "Importons d'abord les librairies nécessaires.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33953c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc90b1b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"f83e124a\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/diabetes-blood-sample.jpeg\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://medicalfitness.com.au/type-1-and-2-diabetes-australia/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4a5eb103\" -->\n",
    "Dans ce module, nous allons appliquer la classification par forêt aléatoire afin de prédire si un sujet\n",
    "est diabétique ou non en fonction de variables mesurés à la suite d'une visite médicale typique (prise\n",
    "de pression, de sang, d'urine, de poids, etc.)\n",
    "\n",
    "Ce type d'analyse a mené à une meilleure compréhension du diabète. C'est un bel exemple de l'utilisation de\n",
    "l'apprentissage automatique en médecine. Dans ce problème, nous sommes confrontés à des données\n",
    "disparates (taux de glucose dans le sang, indice de masse corporelle, épaisseur de la peau, etc.)\n",
    "\n",
    "Comme on l'a vu dans les précédentes sections, la classification sert à prédire une *réponse* $y$, qui est\n",
    "une variable ordinale ou catégorielle (c.-à-d. une classe), en fonction de plusieurs variables $x_{i}$\n",
    "\n",
    "$$y=f(x_{1}, \\cdots, x_{N}, \\Theta)$$\n",
    "\n",
    "où $\\Theta$ représente l'ensemble des paramètres de la fonction $f$.\n",
    "\n",
    "Il est généralement impossible de modéliser exactement cette fonction dû au grand nombre de phénomènes\n",
    "impliqués lors de la prise de données. La modélisation par forêt aléatoire permet de passer outre à la\n",
    "modélisation analytique. Elle permet de modéliser un phénomène impliquant un très grand nombre d'interactions entre les\n",
    "différentes variables sans avoir à les spécifier explicitement dans un modèle mathématique. C'est une des raisons\n",
    "qui expliquent leur immense champ d'applications en sciences de la vie et en sciences sociales par exemple.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8aadf220\" -->\n",
    "# <a id=lecture-et-préparation-des-données>Lecture et préparation des données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"b856da26\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/classifier-model.png\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: Google Image</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"7897e110\" -->\n",
    "Le  jeu de données contient neuf variables, continues ou ordinales, qui ont été mesurées chez 768 sujets:\n",
    "\n",
    "\n",
    "- Pregnancies: nombre de grossesses,\n",
    "- Glucose: taux de glucose,\n",
    "- BloodPressure: pression artérielle,\n",
    "- SkinThickness: épaisseur de la peau,\n",
    "- Insulin: taux d'insuline,\n",
    "- BMI: indice de masse corporelle (IMC), \n",
    "- DiabetesPedigreeFunction: facteur de diabète,\n",
    "- Age: âge,\n",
    "- Outcome: résultat.\n",
    "\n",
    "\n",
    "La dernière, Outcome, contient la réponse binaire que l'on veut prédire. Le sujet est atteint\n",
    "du diabète lorsque Outcome=1.\n",
    "\n",
    "Les données originales ont été extraites du jeu de données\n",
    "[diabetes](https://www.kaggle.com/uciml/pima-indians-diabetes-database). Celle-ci contient toutefois\n",
    "plusieurs valeurs manquantes. Elle a été nettoyée en remplaçant, pour chaque variable sauf Pregnancies et Outcome, les valeurs manquantes par la valeur médiane des valeurs présentes. Dans ce qui suit, nous allons utiliser les données nettoyées.\n",
    "\n",
    "Le but de notre analyse est de déterminer si un sujet est diabétique, ou non, en fonction de ces variables.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du jeu de données en format CSV\n",
    "\n",
    "df = pd.read_csv(\"/pax/shared/GIF-U014/diabetes_nettoyée.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3651a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de statistiques sur les données\n",
    "\n",
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a9fa1",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"a0ffd894\" -->\n",
    "On voit que les valeurs couvrent différents ordres de grandeur. Il faudra les normaliser pour cette raison. Bien que les arbres décisionnels et les forêts aléatoires ne soient pas affectés par la normalisation, c'est une bonne habitude de normaliser ses données.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0739ca01\" -->\n",
    "La colonne `'Unnamed: 0'` contient un indice allant de 0 à 767. Elle est inutile.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop(\"Unnamed: 0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380c6c4",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des variables X et de la réponse y du jeu de données\n",
    "\n",
    "X = df.drop([\"Outcome\"], axis=1)\n",
    "y = df.Outcome\n",
    "\n",
    "# Liste des variables utilisées\n",
    "feature_list = list(X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0530ff4",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"89346c43\" -->\n",
    "Affichons le nombre de données pour chacune pour vérifier s'il y a un débalancement.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind=\"bar\").set_title(\"Diabetes Outcome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b1c99",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"55662d08\" -->\n",
    "La classe 0 comprend environ $65~\\%$ des données. Il y a un léger débalancement des données dont nous allons tenir compte pour la suite de l'analyse.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ac0c6c85\" -->\n",
    "Les données d'entraînement vont servir à entraîner le classificateur. C'est-à-dire, à estimer la valeur du seuil  $\\tau$  de chaque noeud, dans chaque arbre décisionnel de la forêt. Les données de test vont ensuite servir à mesurer les performances du modèle entraîné à prédire correctement si une personne est atteinte ou non du diabète.\n",
    "\n",
    "L'échantillonnage stratifié fait en sorte que les deux ensembles de données contiennent les mêmes proportions de sujets diabétiques et sains.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4406df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération stratifiée des ensembles d'entraînement et de test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c80d5c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"9815a089\" -->\n",
    "Par la suite, nous allons normaliser les données.\n",
    "\n",
    "Les paramètres de la fonction de normalisation doivent être calculés à partir des données\n",
    "d'entraînement uniquement. La même fonction est ensuite appliquée aux ensembles d'entraînement et de test. Il ne\n",
    "faut pas normaliser les données avant de générer les ensembles d'entraînement et de test.\n",
    "\n",
    "Selon l'approche du `StandardScaler`, chaque colonne $x_i$ d'une matrice $X$ est transformée de la façon suivante\n",
    "\n",
    "$$x'_i = \\dfrac{x_i-\\mu_i}{\\sigma_i}$$\n",
    "\n",
    "où $\\mu_i$ et $\\sigma_i$ sont la moyenne et l'écart-type des valeurs de $x_i$, calculés avec les données d'entraînement.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773d51c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"107d9537\" -->\n",
    "Pourquoi les paramètres de la fonction de normalisation doivent-ils être calculés uniquement à partir des données\n",
    "d'entraînement?\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8260384f\" -->\n",
    "# <a id=entraînement-dun-classificateur-de-type-forêt-aléatoire>Entraînement d'un classificateur de type forêt aléatoire</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"dd63ebb5\" -->\n",
    "Initialiser une forêt aléatoire de classification ([`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) (`# À remplir`) avec les paramètres suivants:\n",
    "\n",
    "- une forêt aléatoire de `300` estimateurs (*estimators*),\n",
    "- une profondeur des arbres maximales de `4`, et\n",
    "- un nombre minimal d'exemples (*samples*) de `4` pour diviser une feuille (*internal node*).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de435bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = # À remplir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3f906",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249489b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du classificateur avec les données d'entraînement\n",
    "\n",
    "clf.fit(X_train_s, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0276f",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"2c5266f0\" -->\n",
    "# <a id=affichage-des-statistiques-de-classification>Affichage des statistiques de classification</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e13de826\" -->\n",
    "Nous allons maintenant calculer quelques métriques pour évaluer les performances en classification. Celles-ci sont\n",
    "décrites dans le module sur les métriques de qualité en classification. Il est toutefois utile de les décrire ici brièvement afin de mieux comprendre nos résultats de classification:\n",
    "\n",
    "\n",
    "- Exactitude (*accuracy*): C'est la fraction des prédictions (sujets avec ou sans diabète) qui se sont avérées exactes.\n",
    "- Précision (*precision*): C'est la fraction des prédictions positives (sujets avec diabète) qui se sont avérées exactes.\n",
    "- Rappel (*recall*): C'est la fraction des sujets positifs (avec diabète) qui ont été détectés.\n",
    "- Score $F_1$: C'est la moyenne harmonique de la précision et du rappel. Il est défini comme suit.\n",
    "\n",
    "\n",
    "$$F_1=\\frac{2 *\\text{Précision} *\\text{Rappel}}{\\text{Précision} + \\text{Rappel}}$$\n",
    "\n",
    "Dans une situation où il est difficile de choisir entre les métriques $\\text{Précision}$ et $\\text{Rappel}$, le\n",
    "score $F_1$, qui les combine, est souvent préféré. Pourquoi ne pas simplement utiliser la moyenne arithmétique des deux métriques? Cela est dû au fait que chacune est un pourcentage et donc un ratio. On doit utiliser la moyenne harmonique\n",
    "pour calculer la moyenne de ratios.\n",
    "\n",
    "Voici un exemple. Supposons que la distance entre deux villes est de 120 km. À l'aller, le trajet dure 3 h et au retour il dure 2 h. La vitesse est de $v_a=40$ km/h à l'aller, et de $v_r=60$ km/h au retour. La vitesse moyenne est-elle réellement de $\\bar{v}=(v_a+v_b)/2=50$ km/h? Non! Une distance totale de 240 km a été parcourue en 5 h. La vitesse moyenne est de\n",
    "$\\bar{v} = 240 \\text{ km}/5\\text{ h}=48\\text{ km/h}$. La bonne réponse est la moyenne harmonique:\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "\\bar{v} &= \\frac{2 v_{a} v_{r}}{v_{a} +v_{r}} \\\\\n",
    "        &= \\frac{2 \\times 40 \\times 60 }{40 + 60} \\\\\n",
    "        &= 48\n",
    "\\end{align}$$\n",
    "\n",
    "La différence entre 48 km/h et 50 km/h n'est pas grande, mais elle est réelle.\n",
    "> À noter que l'on calcule souvent la moyenne arithmétique de pourcentages, qui sont des ratios. Ce n'est pas la bonne façon de procéder, mais c'est dans les habitudes.\n",
    "\n",
    "Comme vous le voyez, il y a des subtilités dans les définitions des différentes métriques, mais elles sont importantes.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcd3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour les ensembles d'entraînement et de test\n",
    "\n",
    "pred_train = clf.predict(X_train_s)\n",
    "pred_test = clf.predict(X_test_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367fcb2",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57cb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des valeurs d'exactitude\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données d'entraînement: %0.1f %%\"\n",
    "    % (100 * accuracy_score(y_train, pred_train))\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données de test: %0.1f %%\\n\"\n",
    "    % (100 * accuracy_score(y_test, pred_test))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3577a",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"1dc1bc77\" -->\n",
    "L'exactitude en entraînement est d'environ $83~\\%$ alors que celle en test est d'environ $72~\\%$.\n",
    "Ainsi $72~\\%$ des prédictions effectuées sur de nouveaux sujets, avec ou sans diabète, sont correctes.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"6653ad08\" -->\n",
    "Maintenant, affichons un rapport sur les statistiques de classification. Celui-ci permet d'obtenir une comparaison plus fine des performances en test.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf851eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3cb2d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"ef1c3780\" -->\n",
    "La proportion des résultats positifs qui correspondent réellement à des sujets diabétiques (la précision) est de $64~\\%$.\n",
    "La proportion des sujets diabétiques détectés et qui le sont réellement (le rappel ou *recall*) est de $46~\\%$.\n",
    "\n",
    "On observe des F1-scores de $80~\\%$ pour les cas normaux et de $54~\\%$ pour les cas diabétiques.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ec376d01\" -->\n",
    "# <a id=identification-des-variables-les-plus-importantes-pour-diagnostiquer-le-diabète>Identification des variables les plus importantes pour diagnostiquer le diabète</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0188acbb\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/inspector-with-magnifying-glass.jpeg\"  width=\"200\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: http://clipart-library.com/clipart/1416328.htm</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"eb1eb36d\" -->\n",
    "> À noter que cette section est similaire à celle dans le module montrant un exemple de régression par forêt aléatoire. Toutefois,\n",
    "nous allons la revisiter, car les concepts qui y sont expliqués sont très utiles dans la pratique.\n",
    "\n",
    "Les variables $x_{i}$ les plus importantes sont les plus utilisées pour prendre des décisions à travers les arbres décisionnels constituant la forêt.\n",
    "\n",
    "L'importance de chaque variable correspond au nombre de fois qu'elle est utilisée dans la forêt aléatoire pour prendre une décision. Elle prend une valeur entre 0 et 1, où 0 indique qu'elle n'est jamais utilisée, et où 1 indique qu'elle est la seule utilisée parmi toutes. Dans ce dernier cas, la variable permet de prédire parfaitement la réponse.\n",
    "La somme des importances sur l'ensemble des variables vaut 1.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'importance de chaque variable\n",
    "\n",
    "importances = list(clf.feature_importances_)\n",
    "\n",
    "# Le nom de chaque variable est associé à son importance\n",
    "feature_importances = [\n",
    "    (feature, round(importance, 2))\n",
    "    for feature, importance in zip(feature_list, importances)\n",
    "]\n",
    "\n",
    "# Ordonnancement des valeurs d'importance en ordre décroissant\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746f087",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3a4a6006\" -->\n",
    "On veut déterminer lesquelles sont les plus importantes et combien il y en a. Pour cela, nous allons afficher un diagramme d'importance des variables du jeu de données.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "var = list(range(len(importances)))\n",
    "plt.bar(var, np.array(importances)[indices.astype(int)], orientation=\"vertical\")\n",
    "plt.xticks(var, np.array(feature_list)[indices.astype(int)], rotation=\"vertical\")\n",
    "plt.ylabel(\"Importance\", fontsize=16)\n",
    "plt.xlabel(\"Variable\", fontsize=16)\n",
    "plt.title(\"Importance des variables\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d61a95",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"b934ad71\" -->\n",
    "On remarque qu'il n'y a pas de séparation franche entre les variables. Toutefois, il semble y avoir un léger « coude » dans la distribution à la quatrième variable. Ainsi, les quatre premières variables semblent être les plus\n",
    "importantes, soit en ordre décroissant:\n",
    "\n",
    "- le taux de glucose,\n",
    "- l'indice de masse corporelle (BMI),\n",
    "- l'âge,\n",
    "- le taux d'insuline.\n",
    "\n",
    "Notez bien que ces résultats ne sont valides que pour ce  jeu de données et pour le type de prétraitement utilisé. En effet, l'ordre précis des variables indicatrices peut légèrement changer en fonction du type de prétraitement ou du classificateur utilisés.\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
