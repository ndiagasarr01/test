{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1af05fe",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"453d324d\" -->\n",
    "# Table des matières\n",
    "1. [Qu'est-ce que le biais et la variance?](#quest-ce-que-le-biais-et-la-variance)\n",
    "1. [Comment calculer le biais et la variance en régression?](#comment-calculer-le-biais-et-la-variance-en-régression)\n",
    "1. [La relation entre le MSE, le biais et la variance](#la-relation-entre-le-mse-le-biais-et-la-variance)\n",
    "    1. [Calcul du MSE, du $\\text{biais}^2$ et de la variance](#calcul-du-mse-du-biais-et-de-la-variance)\n",
    "      1. [Comparaison des mesures du MSE avec la relation théorique](#comparaison-des-mesures-du-mse-avec-la-relation-théorique)\n",
    "1. [Quel est le polynôme recalant le mieux les données?](#quel-est-le-polynôme-recalant-le-mieux-les-données)\n",
    "1. [Comparaison des courbes du MSE en entraînement et en test](#comparaison-des-courbes-du-mse-en-entraînement-et-en-test)\n",
    "1. [Exemples de sous-apprentissage et de surapprentissage en régression](#exemples-de-sous-apprentissage-et-de-surapprentissage-en-régression)\n",
    "    1. [Sous-apprentissage](#sous-apprentissage)\n",
    "    1. [Surapprentissage](#surapprentissage)\n",
    "    1. [Le juste milieu](#le-juste-milieu)\n",
    "1. [Le sous-apprentissage et le surapprentissage en classification](#le-sous-apprentissage-et-le-surapprentissage-en-classification)\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa01e9b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3f16da2d\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/under-vs-over-training.jpeg\"  width=\"600\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://datacadamia.com/data_mining/overfitting</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"beb23636\" -->\n",
    "Dans ce module, nous allons discuter des phénomènes de sous-apprentissage (*Underfitting*) et de surapprentissage (*Overfitting*) que l'on observe\n",
    "régulièrement en apprentissage automatique. Nous allons aborder le sujet en nous concentrant sur\n",
    "la régression et allons utiliser des modèles polynomiaux pour recaler des données expérimentales. Ils sont faciles à\n",
    "utiliser et les deux phénomènes sont faciles à visualiser avec ceux-ci.\n",
    "\n",
    "Pour ce faire, nous allons discuter de la métrique de l'erreur quadratique moyenne (MSE) qui permet de déterminer\n",
    "le modèle optimal pour analyser les données. Celui-ci se trouve au juste milieu, entre les\n",
    "modèles victimes de l'un ou de l'autre des phénomènes d'apprentissage. L'erreur quadratique moyenne dépend du biais (*Bias*)\n",
    "et de la variabilité des mesures.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a70c00f9\" -->\n",
    "# <a id=quest-ce-que-le-biais-et-la-variance>Qu'est-ce que le biais et la variance?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e5660c17\" -->\n",
    "Le biais mesure la différence entre le signal idéal et le signal moyen estimé. Supposons que vous avez un\n",
    "thermomètre et que vous mesurez un grand nombre de fois la température de l'eau bouillante. Vous prenez la moyenne des\n",
    "mesures et vous obtenez $103 ^\\circ C$. Puisque l'eau bout $100 ^\\circ C$ (au niveau de la mer) il y a une erreur\n",
    "systématique de $3 ^\\circ C$; c'est le biais. La mesure du thermomètre est biaisée. On peut éliminer ce biais en calibrant\n",
    "le thermomètre.\n",
    "\n",
    "La variance mesure la variabilité des résultats. Reprenons l'exemple du thermomètre, maintenant calibré. Si vous\n",
    "mesurez plusieurs fois la température de l'eau bouillante, vous allez obtenir des valeurs comme suit:\n",
    "$99,8$$^\\circ C$; $100,3$$^\\circ C$; $99,5$$^\\circ C$; $100,1$$^\\circ C$; etc. Ces données ont un écart-type d'environ\n",
    "$0,3$$^\\circ C$ et une variance de $0,09$$^\\circ C^2$. Idéalement, l'affichage du thermomètre\n",
    "indiquerait toujours une température de $100^\\circ C$, c'est-à-dire, sans biais ni variabilité dans les mesures.\n",
    "\n",
    "La figure suivante montrant des cibles de dards résume bien la situation. Le premier panneau montre le cas\n",
    "d'un thermomètre typique bien ajusté; les données sont bien centrées (erreur moyenne nulle) et\n",
    "varient peu (variance faible). Le panneau en bas à gauche correspond au thermomètre mal calibré; précis, mais\n",
    "avec une erreur systématique. Le tableau en haut à droite correspond au thermomètre bien calibré, mais\n",
    "imprécis, c'est-à-dire, avec une grande variabilité (erreurs de mesures trop grandes). Enfin, le panneau en bas, à droite\n",
    "correspond à la pire situation; un thermomètre mal calibré et imprécis.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e6dc2b44\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/biais-variance-diagram.png\"  width=\"400\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://tex.stackexchange.com/questions/307117/reconstructing-the-following-bias-variance-diagram</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1ff09b30\" -->\n",
    "# <a id=comment-calculer-le-biais-et-la-variance-en-régression>Comment calculer le biais et la variance en régression?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"eaff2c28\" -->\n",
    "Supposons que l'on essaie de mesurer une fonction inconnue $f$\n",
    "\n",
    "$$y = f(x)$$\n",
    "\n",
    "et que l'on obtienne des mesures expérimentales\n",
    "\n",
    "$$y'^{(i)} = f(x^{(i)}) + \\text{bruit}^{(i)}$$\n",
    "\n",
    "L'indice $i$ représente le numéro d'une donnée tel que $1\\le i \\le n$, où $n$ est le nombre de données. Nous allons recaler un modèle polynomial aux données expérimentales afin d'approximer $f$.\n",
    "Afin de simplifier l'écriture, on va utiliser la convention suivante pour\n",
    "décrire un polynôme de degré donné avec les paramètres $\\Theta_j$. L'indice $j$ indique que les paramètres ont été\n",
    "estimés pour un ensemble de données $(x,y')_j$. Le degré du polynôme est constant dans la discussion.\n",
    "\n",
    "$$\\hat{y} = h(x|\\Theta_j)$$\n",
    "\n",
    "Dans ce qui suit, chaque ensemble de données $(x,y')_j$ est séparé en un ensemble d'entraînement et un de test. Un modèle est entraîné avec l'ensemble de test, et les métriques $\\text{biais}^2$, $\\text{variance}$ et $\\text{MSE}$ sont calculées avec l'ensemble de test.\n",
    "\n",
    "Si l'on génère N ensembles de données bruitées $(x,y')_j$ aux mêmes valeurs de $x$, puis qu'on recale un\n",
    "polynôme à chaque ensemble, et qu'enfin on calcule la moyenne des N polynômes, on obtient le modèle moyen\n",
    "\n",
    "$$m(x^{(i)}) = \\frac{1}{N}\\sum_{j=1} ^{N}h(x^{(i)}|\\Theta_j)$$\n",
    "\n",
    "Le biais mesure la différence entre la fonction inconnue $f$ et le modèle moyen $m$. Idéalement,\n",
    "il serait nul partout.\n",
    "\n",
    "$$b(x^{(i)}) = f(x^{(i)}) - m(x^{(i)})$$\n",
    "\n",
    "On utilise la notation $\\text{biais}^2$ pour indiquer la moyenne du carré du biais. On le calcule comme suit:\n",
    "\n",
    "$$\\text{biais}^2 = \\frac{1}{n}\\sum_{i=1} ^{n}b(x^{(i)})^2$$\n",
    "\n",
    "La variance des erreurs entre le modèle moyen $m$ et chacun des N polynômes précédents est\n",
    "\n",
    "$$\\text{variance} = \\frac{1}{Nn}\\sum_{j=1}^{N}\\sum_{i=1}^{n}(m(x^{(i)})-h(x^{(i)}|\\Theta_j))^2$$\n",
    "\n",
    "L'erreur quadratique moyenne est définie comme suit\n",
    "$$\\text{MSE} = \\frac{1}{Nn}\\sum_{j=1}^{N}\\sum_{i=1}^{n}(y'^{(i)}-h(x^{(i)}|\\Theta_j))^2$$\n",
    "\n",
    "On peut montrer la relation suivante entre les trois quantités\n",
    "$$\\text{MSE} = \\text{biais}^{2} + \\text{variance} + \\sigma^2$$\n",
    "\n",
    "où $\\sigma^2$ est la variance du bruit gaussien dans les données.\n",
    "\n",
    "Comme on le verra à plusieurs reprises dans ce module, cette relation permet de décrire les effets du sous-apprentissage et de surapprentissage. Ces problèmes sont omniprésents dans la pratique courante de l'apprentissage automatique. Il est  bien de s'y familiariser tôt afin de comprendre les résultats de nos entraînements.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1afe87ef\" -->\n",
    "# <a id=la-relation-entre-le-mse-le-biais-et-la-variance>La relation entre le MSE, le biais et la variance</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"731af095\" -->\n",
    "Définissons d'abord quelques fonctions qui seront utilisées à plusieurs reprises. Par la suite, nous allons générer le vrai signal idéal que l'on va utiliser pour générer les données. Ce signal sera généré selon la fonction sinusoïdale suivante\n",
    "\n",
    "$$y = 100\\sin(10x).$$\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du signal idéal\n",
    "def vrai_signal(x):\n",
    "    y = 100 * np.sin(10 * x)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Génération d'échantillons du signal idéal et ajout de bruit gaussien.\n",
    "# Les valeurs de x sont réparties aléatoirement sur la plage des valeurs\n",
    "# disponibles.\n",
    "def genere_signal_bruité(N):\n",
    "    x = np.random.uniform(x_min, x_max, N)\n",
    "    y = vrai_signal(x) + np.random.normal(0.0, sigma, N)\n",
    "\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Régression à un polynôme de degré donné\n",
    "def regression_polynome(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33229a0d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62405568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du signal idéal pour des valeurs de x réparties uniformément\n",
    "\n",
    "x_min = 0\n",
    "x_max = 1\n",
    "\n",
    "xx = np.linspace(x_min, x_max, 100)[:, np.newaxis]\n",
    "yy = vrai_signal(xx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986e910",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du signal expérimental (c.-à-d. bruité) pour des valeurs de x réparties aléatoirement\n",
    "\n",
    "sigma = 20  # Niveaux de bruit\n",
    "N = 20  # Nombres de points du signal\n",
    "X_data, y_data = genere_signal_bruité(N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01879f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du signal idéal pour les mêmes valeurs de x\n",
    "\n",
    "y_vrai = vrai_signal(X_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9af9d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"68d6ee4c\" -->\n",
    "Dans ce qui suit, on va générer divers ensembles d'entraînement et de test qui utiliseront toujours les mêmes valeurs de x réparties aléatoirement. On peut donc écrire:\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_data\n",
    "X_test = X_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9c9b9",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"77e46309\" -->\n",
    "# <a id=calcul-du-mse-du-biais-et-de-la-variance>Calcul de le MSE, du $\\text{biais}^2$ et de la variance</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4c9100ab\" -->\n",
    "Pour chaque degré de polynôme entre 0 et 12, on génère 1 000 signaux bruités. Chacun est recalé au polynôme\n",
    "associé. On calcule ensuite l'erreur quadratique moyenne, le $\\text{biais}^2$ et la variance pour ces 1 000 ensembles de données.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093226",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 1000\n",
    "n_degres = 12\n",
    "degres = range(n_degres)\n",
    "\n",
    "hx = np.zeros((N, n_rep))\n",
    "biais2 = np.zeros(n_degres)\n",
    "variance = np.zeros(n_degres)\n",
    "mse = np.zeros(n_degres)\n",
    "\n",
    "for degre in degres:\n",
    "    sse = 0\n",
    "    for n in range(n_rep):\n",
    "        # Génération de données d'entraînement et de test aux même valeurs de x\n",
    "        y_train = y_vrai + np.random.normal(0.0, sigma, N).reshape(-1, 1)\n",
    "        y_test = y_vrai + np.random.normal(0.0, sigma, N).reshape(-1, 1)\n",
    "\n",
    "        # Entraînement du modèle polynomial avec les données d'entraînement\n",
    "        reg = regression_polynome(degre).fit(X_train, y_train)\n",
    "\n",
    "        # Prédiction des valeurs de y pour les données de test\n",
    "        y_pred = reg.predict(X_test)\n",
    "        hx[:, n] = np.squeeze(y_pred, axis=1)\n",
    "\n",
    "        # Erreur de recalage en test\n",
    "        erreurs = y_pred - y_test\n",
    "\n",
    "        # Ajout à la somme des carrés des erreurs (SSE)\n",
    "        sse += np.square(erreurs).mean()\n",
    "\n",
    "    # Calcule le signal recalé moyen\n",
    "    E_hx = np.mean(hx, 1).reshape(-1, 1)\n",
    "\n",
    "    # Calcule le biais^2 entre le signal original et le signal recalé moyen\n",
    "    biais2[degre] = np.square(E_hx - y_vrai).mean()\n",
    "\n",
    "    # Calcule la variance entre le signal original et le signal recalé moyen\n",
    "    variance[degre] = np.square(E_hx - hx).mean()\n",
    "\n",
    "    # Calcule l'erreur moyenne\n",
    "    mse[degre] = sse / n_rep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16faa7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la relation entre l'erreur quadratique moyenne, le biais et la variance\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(degres, biais2, color=\"red\", label=\"$biais^{2}$\", linestyle=\"--\")\n",
    "plt.plot(degres, variance, color=\"blue\", label=\"variance\", linestyle=\"--\")\n",
    "plt.plot(degres, mse, color=\"black\", label=\"MSE\")\n",
    "plt.legend(loc=\"best\", facecolor=\"wheat\", shadow=True)\n",
    "plt.xlabel(\"Degré\", fontsize=18)\n",
    "plt.ylabel(\"Erreur\", fontsize=18)\n",
    "plt.xlim([1, n_degres])\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee0f42",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3f7d4938\" -->\n",
    "On voit que le biais diminue avec le degré du polynôme alors que la variance augmente avec celui-ci. Nous verrons plus loin ce que cela signifie en pratique avec des signaux analysés.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a27b3989\" -->\n",
    "### <a id=comparaison-des-mesures-du-mse-avec-la-relation-théorique>Comparaison des mesures du MSE avec la relation théorique</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"7213bced\" -->\n",
    "La figure suivante montre la superposition des deux courbes.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    degres,\n",
    "    biais2 + variance + sigma * sigma,\n",
    "    color=\"red\",\n",
    "    label=\"$variance + biais^{2} + \\sigma^2$\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=10,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(degres, mse, color=\"black\", label=\"MSE\")\n",
    "plt.legend(loc=\"best\", facecolor=\"wheat\", shadow=True)\n",
    "plt.xlabel(\"Degré\", fontsize=18)\n",
    "plt.ylabel(\"Erreur\", fontsize=18)\n",
    "plt.xlim([1, n_degres])\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2c03f",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"9da027c7\" -->\n",
    "On observe bien la relation théorique\n",
    "\n",
    "$$\\text{MSE} = \\text{biais}^{2} + \\text{variance} + \\sigma^2.$$\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ac3bfd4d\" -->\n",
    "# <a id=quel-est-le-polynôme-recalant-le-mieux-les-données>Quel est le polynôme recalant le mieux les données?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ed1c0251\" -->\n",
    "C'est celui minimisant l'erreur quadratique moyenne. Déterminons le degré de ce polynôme.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffef99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.argmin(mse)\n",
    "degre_opt = degres[indx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9df9c1",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"0278c804\" -->\n",
    "On calcule ensuite les valeurs de la réponse $y$ pour des valeurs de x réparties uniformément.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_opt = regression_polynome(degre_opt).fit(X_data, y_data).predict(xx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2af32",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b10278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du vrai signal, du recalage optimal et des données bruitées originales\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_data.ravel(), y_data, color=\"blue\")\n",
    "lim = plt.axis()\n",
    "plt.plot(xx, yy, label=\"vrai signal\", color=\"blue\")\n",
    "plt.plot(xx, y_pred_opt, label=\"polynôme\", color=\"r\")\n",
    "plt.legend(loc=\"best\", facecolor=\"wheat\", shadow=True)\n",
    "plt.xlabel(\"X\", fontsize=18)\n",
    "plt.ylabel(\"Y\", rotation=0, fontsize=18)\n",
    "plt.title(\"Polynôme optimal de degré = %d\" % (degre_opt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810cc0d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"f19583d4\" -->\n",
    "On voit que le polynôme optimal reproduit bien la distribution des données expérimentales ainsi que l'aspect général du vrai signal.\n",
    "\n",
    "Les prédictions pour des valeurs de x aux extrémités (hors de la plage originale des données (extrapolations)),\n",
    "sont moins bonnes que celles pour des valeurs de x à l'intérieur (interpolations).\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"df41c185\" -->\n",
    "## <a id=comparaison-des-courbes-du-mse-en-entraînement-et-en-test>Comparaison des courbes du MSE en entraînement et en test</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"98a4a6e1\" -->\n",
    "Plus le degré d'un polynôme est élevé, plus grande est sa complexité. Dans cette section, nous utilisons\n",
    "deux ensembles de données bruitées: un ensemble d'entraînement et un autre de test.\n",
    "\n",
    "Chaque modèle polynomial est entraîné avec les données d'entraînement. On utilise ensuite\n",
    "le modèle résultant pour prédire les valeurs du signal débruité pour les données d'entraînement et de test.\n",
    "La valeur du MSE est enfin calculée pour chaque ensemble de données. L'opération est effectuée 1 000\n",
    "fois afin d'obtenir de meilleures statistiques.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "n_rep = 1000\n",
    "\n",
    "mse_train = np.zeros(n_degres)\n",
    "mse_test = np.zeros(n_degres)\n",
    "\n",
    "for degre in degres:\n",
    "    sse_train, sse_test = 0, 0\n",
    "    for n in range(n_rep):\n",
    "        # Génération des deux ensembles de données bruitées\n",
    "        X_train, y_train = genere_signal_bruité(N)\n",
    "        X_test, y_test = genere_signal_bruité(N)\n",
    "\n",
    "        # Entraînement du modèle polynomial avec les données d'entraînement\n",
    "        reg = regression_polynome(degre).fit(X_train, y_train)\n",
    "\n",
    "        # --- Ensemble d'entraînement ---\n",
    "        # Prédiction des valeurs du signal débruité\n",
    "        y_pred = reg.predict(X_train)\n",
    "\n",
    "        # Prédiction des vraies valeurs du signal\n",
    "        y = vrai_signal(X_train)\n",
    "\n",
    "        # Erreurs de prédiction\n",
    "        erreurs = y_pred - y\n",
    "\n",
    "        # Cumul de la moyenne des erreurs au carré\n",
    "        sse_train += np.square(erreurs).mean()\n",
    "\n",
    "        # --- Ensemble de test ---\n",
    "        y_pred = reg.predict(X_test)\n",
    "        y = vrai_signal(X_test)\n",
    "        erreurs = y_pred - y\n",
    "        sse_test += np.square(erreurs).mean()\n",
    "\n",
    "    # Calcul du MSE pour les deux ensembles de données\n",
    "    mse_train[degre] = sse_train / n_rep\n",
    "    mse_test[degre] = sse_test / n_rep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d7f1f",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"6e80a039\" -->\n",
    "Affichage des résultats comparant les deux courbes du MSE en fonction de la complexité\n",
    "du modèle de régression (le degré du polynôme).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(degres, mse_train, color=\"#48D1CC\", linewidth=3, label=\"Train\")\n",
    "plt.plot(degres, mse_test, color=\"red\", linewidth=3, label=\"Test\")\n",
    "plt.legend(loc=\"best\", facecolor=\"wheat\", shadow=True)\n",
    "plt.xlabel(\"Degré (Complexité)\")\n",
    "plt.ylabel(\"Erreur\")\n",
    "plt.xlim([1, n_degres])\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bfaf7",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3c212e62\" -->\n",
    "La figure montre deux comportements différents du MSE selon que l'on considère les données d'entraînement (*Train*) ou de test.\n",
    "Discutons d'abord des résultats d'entraînement.\n",
    "\n",
    "La courbe en vert montre que plus un modèle de régression est complexe, plus le MSE est faible.\n",
    "Ce n'est pas vraiment surprenant puisqu'il dispose de plus de paramètres à ajuster finement afin de mieux s'adapter à\n",
    "la distribution des données de test.\n",
    "\n",
    "La courbe pour les données de test, en rouge, montre que le MSE décroît initialement jusqu'au degré 6, puis\n",
    "croît par la suite. C'est le degré du polynôme optimal déterminé précédemment.\n",
    "\n",
    "Les résultats présentés dans la figure dépendent du modèle de recalage utilisé. Ils auraient été différents\n",
    "avec un autre modèle de régression. Néanmoins, la figure suivante montre l'aspect général des courbes\n",
    "de MSE qu'on obtient dans la pratique. C'est ce qu'il faut retenir ici.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"5bac3c8e\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/under-vs-over-training.jpeg\"  width=\"600\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://datacadamia.com/data_mining/overfitting</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e9b68175\" -->\n",
    "Le MSE en entraînement diminue graduellement alors que celle de test passe par un minimum avant d'augmenter ensuite.\n",
    "La courbe de test peut être séparée en deux zones. La zone à gauche du minimum correspond à des modèles trop\n",
    "simples par rapport à la distribution des données; on y associe le phénomène du sous-apprentissage.\n",
    "\n",
    "La zone à droite du minimum correspond à des modèles inutilement complexes; c'est le domaine du surapprentissage.\n",
    "Chaque modèle entraîné contient beaucoup de paramètres pouvant être finement ajustés afin de passer près des données.\n",
    "On dit alors qu'il apprend à 'mémoriser' la position des données d'entraînement, et donc le bruit dans celles-ci.\n",
    "Puisque le bruit dans les données de test est différent, les données à recaler sont différentes de celles 'mémorisées'.\n",
    "Le modèle ne peut les prédire aussi bien que celles d'entraînement. Le problème est d'autant plus important que le modèle\n",
    "est complexe. Les erreurs de prédiction augmentent, et donc le MSE en test.\n",
    "\n",
    "La séparation entre les deux zones indique le modèle optimal qui est juste assez complexe pour reproduire\n",
    "l'aspect des données, mais pas assez pour les « mémoriser ».\n",
    "\n",
    "La partie suivante explique graphiquement chacun des comportements que l'on vient de décrire.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"2961ce95\" -->\n",
    "# <a id=exemples-de-sous-apprentissage-et-de-surapprentissage-en-régression>Exemples de sous-apprentissage et de surapprentissage en régression</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"20fb4a0f\" -->\n",
    "Définissons d'abord quelques fonctions qui seront utilisées à plusieurs reprises\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e224f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction affichant le vrai signal et les données expérimentales\n",
    "def plot_data(ax):\n",
    "    ax.scatter(X_data, y_data, color=\"black\")\n",
    "    ax.plot(xx, yy)\n",
    "    ax.plot([xx.min(), xx.max()], [0, 0], color=\"black\", linestyle=\"--\")\n",
    "    ax.set_ylim([-150, 150])\n",
    "    ax.set_xlabel(\"X\", fontsize=14)\n",
    "    ax.set_ylabel(\"Y\", rotation=0, fontsize=14)\n",
    "    ax.set_title(\"Données expérimentales\")\n",
    "\n",
    "\n",
    "# Fonction affichant plusieurs régressions avec un polynôme de degré donné\n",
    "def fit_poly(degre, N, ax):\n",
    "    N = 50\n",
    "    n_rep = 5\n",
    "    for n in range(n_rep):\n",
    "        X, y = genere_signal_bruité(N)\n",
    "        y_pred = regression_polynome(degre).fit(X, y).predict(xx)\n",
    "        ax.plot(xx, y_pred)\n",
    "\n",
    "    ax.plot([xx.min(), xx.max()], [0, 0], color=\"black\", linestyle=\"--\")\n",
    "    ax.set_ylim([-150, 150])\n",
    "    ax.set_xlabel(\"X\", fontsize=14)\n",
    "    ax.set_ylabel(\"Y\", rotation=0, fontsize=14)\n",
    "    ax.set_title(\"Degré du polynôme = %d\" % (degre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc6bc6",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d8c4613f\" -->\n",
    "Débutons par générer plusieurs exemples de régression pour des polynômes de degrés variés. Le premier panneau de la figure suivante montre un exemple du signal à recaler avec les divers modèles polynomiaux. La courbe correspond au vrai signal utilisé\n",
    "\n",
    "$$y = 100\\sin(10x)$$\n",
    "\n",
    "et les points simulent des données expérimentales.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b43c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "degres = [1, 2, 6, 13, 15]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 12))\n",
    "plot_data(axes[0, 0])\n",
    "fit_poly(degres[0], N, axes[0, 1])\n",
    "fit_poly(degres[1], N, axes[0, 2])\n",
    "fit_poly(degres[2], N, axes[1, 0])\n",
    "fit_poly(degres[3], N, axes[1, 1])\n",
    "fit_poly(degres[4], N, axes[1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f814c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"a390d083\" -->\n",
    "## <a id=sous-apprentissage>Sous-apprentissage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"abf095b1\" -->\n",
    "Les résultats pour les polynômes de faibles degrés, 1 et 2, sont trop simples pour reproduire\n",
    "les détails du signal idéal (courbe en bleu dans le premier panneau). Ils sont tellement\n",
    "différents du signal original qu'il existe une différence importante entre celui-ci et la moyenne des cinq courbes\n",
    "dans chaque panneau (non représentée ici, mais facile à visualiser).\n",
    "La variance des courbes n'est pas très grande. Cette situation (grand biais, faible variance) caractérise\n",
    "le phénomène du sous-apprentissage. Il est illustré dans le premier panneau de la\n",
    "figure suivante, montrant à nouveau de diagramme des dards sur une cible.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"3fd7d221\" -->\n",
    "## <a id=surapprentissage>Surapprentissage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0fba4cd4\" -->\n",
    "Les résultats pour les polynômes de degrés élevés, 13 et 15, reproduisent mieux l'aspect général\n",
    "du signal idéal. La moyenne des cinq courbes dans chaque panneau serait assez similaire à celui-ci.\n",
    "Toutefois, les résultats varient grandement aux extrémités de la plage des valeurs de x. Ils ont une\n",
    "grande variance. Ainsi, les signaux recalés sont plus complexes que le signal original. Cette\n",
    "situation (faible biais, grande variance) caractérise le phénomène du surapprentissage. Il est\n",
    "illustré dans le panneau en bas à droite dans la figure suivante.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0eedff25\" -->\n",
    "## <a id=le-juste-milieu>Le juste milieu</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ee9f5d97\" -->\n",
    "Les résultats pour le polynôme de degré 6 sont les meilleurs. La moyenne des cinq courbes\n",
    "serait similaire à celle du signal original. Les résultats\n",
    "ont aussi une faible variabilité que l'on observe aux extrémités de la plage des valeurs de x. Cette\n",
    "situation, faibles biais et variance, est illustrée dans le panneau en bas à\n",
    "gauche dans la figure suivante.\n",
    "\n",
    "Les résultats optimaux observés précédemment au minimum de la courbe de l'erreur quadratique moyenne en test\n",
    "(polynôme de degré 6) correspondent bien à la situation idéale où tous les dards se\n",
    "trouveraient concentrés au centre de la cible.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e32c7d0b\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/overfitting-illustration.jpeg\"  width=\"300\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://datacadamia.com/data_mining/overfitting</font>\n",
    "    </div>\n",
    "</div>\n",
    "<p>&nbsp;</p>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"f702f597\" -->\n",
    "# <a id=le-sous-apprentissage-et-le-surapprentissage-en-classification>Le sous-apprentissage et le surapprentissage en classification</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"319cc225\" -->\n",
    "Les deux phénomènes sont également rencontrés en classification. La figure suivante en montre des\n",
    "exemples en classification binaire, c'est-à-dire, où il n'y a que deux classes. On observe ceci:\n",
    "\n",
    "- le panneau de gauche montre un cas de sous-apprentissage. La frontière linéaire entre les deux classes est\n",
    "trop simple pour reproduire la distribution des données de chaque classe. Il en résulte plusieurs erreurs de\n",
    "classification (8 croix et 1 cercle),\n",
    "- le panneau de droite montre un cas de surapprentissage. Bien qu'elle ne résulte en aucune erreur\n",
    "de classification, la frontière entre les deux classes est trop complexe pour être crédible. Lors\n",
    "de son entraînement, le classificateur à fini par mémoriser la classe de chaque point afin de bien le classifier,\n",
    "- le panneau central montre le meilleur compromis. La frontière, en arc de cercle, entre les deux\n",
    "classes reproduit assez bien, mais pas parfaitement, la distribution des données de chaque classe. En effet,\n",
    "il demeure quelques erreurs de classification (1 croix et 1 cercle).\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8b79f0fb\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/biais-variance-illustration.png\"  width=\"700\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://x-wei.github.io/Ng_DLMooc_c2wk1.html</font>\n",
    "    </div>\n",
    "</div>\n",
    "<p>&nbsp;</p>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"275a2a9d\" -->\n",
    "Chaque frontière de décision résulte de l'entraînement d'un classificateur avec les données d'entraînement.\n",
    "Si l'on refaisait les entraînements précédents avec de nouvelles données, réparties aléatoirement de\n",
    "façons similaires, on observerait ceci:\n",
    "\n",
    "- panneau de gauche: la frontière linéaire aurait une orientation différente, mais serait toujours\n",
    "aussi mauvaise à séparer les deux classes.\n",
    "\n",
    "- panneau de droite: la séparation des courbes serait à nouveau parfaite, toujours aussi complexe,\n",
    "mais avec des détails très différents. Ce n'est pas réaliste.\n",
    "\n",
    "- panneau central: c'est la frontière qui aurait le moins changé. Il y aurait encore\n",
    "des erreurs de classification, mais la stabilité de la frontière indiquerait que c'est la\n",
    "plus robuste face aux changements de données. C'est ce que l'on recherche chez un classificateur; un minimum\n",
    "d'erreurs de classification avec une frontière variant peu avec de nouvelles données.\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
