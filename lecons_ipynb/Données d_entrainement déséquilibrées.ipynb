{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09981e1",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    formats: md,ipynb\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"bcc96043\" -->\n",
    "# Table des matières\n",
    "1. [Le paradoxe de l'exactitude](#le-paradoxe-de-lexactitude)\n",
    "1. [Avoir $99~\\%$ au test sans étudier!](#avoir-99-au-test-sans-étudier)\n",
    "1. [Tactiques éprouvées pour combattre le débalancement des classes](#tactiques-éprouvées-pour-combattre-le-débalancement-des-classes)\n",
    "  1. [Collecter plus de données!!!](#collecter-plus-de-données)\n",
    "  1. [Changer de métrique de performance](#changer-de-métrique-de-performance)\n",
    "  1. [Ré-échantillonner le jeu de données](#ré-échantillonner-le-jeu-de-données)\n",
    "  1. [Générer des échantillons synthétiques](#générer-des-échantillons-synthétiques)\n",
    "  1. [Essayer les modèles pénalisés](#essayer-les-modèles-pénalisés)\n",
    "1. [Exemples de ré-échantillonnage](#exemples-de-ré-échantillonnage)\n",
    "    1. [Lecture d'un jeu de données déséquilibré contenant deux classes](#lecture-dun-jeu-de-données-débalancé-contenant-deux-classes)\n",
    "    1. [Le piège des métriques](#le-piège-des-métriques)\n",
    "    1. [Techniques de bases en ré-échantillonnage](#techniques-de-bases-en-ré-échantillonnage)\n",
    "      1. [Sous-échantillonnage aléatoire](#sous-échantillonnage-aléatoire)\n",
    "      1. [Suréchantillonnage aléatoire](#suréchantillonnage-aléatoire)\n",
    "    1. [Techniques plus avancées en ré-échantillonnage](#techniques-plus-avancées-en-ré-échantillonnage)\n",
    "      1. [Génération d'un nouveau jeu de données](#génération-dun-nouveau-jeu-de-données)\n",
    "      1. [Sous-échantillonnage aléatoire avec apprentissage déséquilibré](#sous-échantillonnage-aléatoire-avec-apprentissage-déséquilibré)\n",
    "      1. [Suréchantillonnage aléatoire avec apprentissage déséquilibré](#suréchantillonnage-aléatoire-avec-apprentissage-déséquilibré)\n",
    "      1. [Sous-échantillonnage avec liens Tomek](#sous-échantillonnage-avec-liens-tomek)\n",
    "      1. [Sous-échantillonnage avec centroïdes de regroupements](#sous-échantillonnage-avec-centroïdes-de-regroupements)\n",
    "      1. [Suréchantillonnage avec SMOTE](#suréchantillonnage-avec-smote)\n",
    "      1. [Suréchantillonnage suivi d'un sous-échantillonnage](#suréchantillonnage-suivi-dun-sous-échantillonnage)\n",
    "1. [Pour en savoir plus](#pour-en-savoir-plus)\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import (ClusterCentroids, RandomUnderSampler,\n",
    "                                     TomekLinks)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6aa7a",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5054b330\" -->\n",
    "# <a id=le-paradoxe-de-lexactitude>Le paradoxe de l'exactitude</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"f29c7e62\" -->\n",
    "En apprentissage automatique l'[exactitude](https://fr.wikipedia.org/wiki/Exactitude_et_précision) (*accuracy*)\n",
    "est une mesure de qualité en classification. Il existe plusieurs autres mesures de qualité; elles sont présentées\n",
    "dans le module sur les métriques de qualité en classification. L'exactitude est la métrique la plus intuitive de toutes.\n",
    "Elle représente la proportion de prédictions correctes (positives et négatives) parmi l'ensemble des prédictions.\n",
    "\n",
    "Le [paradoxe de l'exactitude](https://en.wikipedia.org/wiki/Accuracy_paradox) est le nom de la situation où vos mesures d'exactitude indiquent que vous avez une excellente exactitude (telle que $90~\\%$), mais que l'exactitude ne reflète que la distribution de classe majoritaire sous-jacente.\n",
    "\n",
    "C'est un problème très courant, car l'exactitude est souvent la première mesure utilisée pour évaluer nos modèles dans les problèmes de classification.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a71d5839\" -->\n",
    "# <a id=avoir-99-au-test-sans-étudier>Avoir $99~\\%$ au test sans étudier!</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"75538af5\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/machine-learning-monitoring.png\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://evidentlyai.com/blog/machine-learning-monitoring-what-it-is-and-how-it-differs/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"578975c1\" -->\n",
    "Que se passe-t-il dans les modèles lorsque l'entraînement est fait sur un jeu de données déséquilibré?\n",
    "\n",
    "Lorsqu'une exactitude de $99~\\%$ est obtenue avec des données déséquilibrées (avec $99~\\%$ des instances dans la « classe 1 »),\n",
    "c'est parce que les modèles examinent les données et décident intelligemment que la meilleure chose à faire est\n",
    "de toujours prédire « classe 1 » pour atteindre une grande exactitude.\n",
    "\n",
    "Est-ce si mauvais que ça? **Oui!** Pensez-y. Dans la pratique, ce sont les instances de la classe rarissime qui nous\n",
    "intéressent réellement. Le classificateur précédent ne pourrait en détecter aucune dans un jeu de données ne\n",
    "contenant que des instances rarissimes!\n",
    "\n",
    "Comment régler ce problème ?\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"610c8e8a\" -->\n",
    "# <a id=tactiques-éprouvées-pour-combattre-le-débalancement-des-classes>Tactiques éprouvées pour combattre le débalancement des classes</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"3bec506c\" -->\n",
    "## <a id=collecter-plus-de-données>Collecter plus de données!!!</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"6cb7bfca\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/more-data-illustration.jpeg\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://technofaq.org/posts/2020/06/3-ways-that-technology-improves-productivity/</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"b89f60d9\" -->\n",
    "Vous pensez peut-être que c'est idiot, mais la collecte de plus de données est presque toujours négligée.\n",
    "\n",
    "Pouvez-vous collecter plus de données? Prenez une seconde et demandez-vous si vous êtes capable de collecter plus de données sur votre problème.\n",
    "\n",
    "Un ensemble de données plus volumineux pourrait exposer une perspective différente et peut-être plus équilibrée des classes.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8b73b21c\" -->\n",
    "## <a id=changer-de-métrique-de-performance>Changer de métrique de performance</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9b68f2f2\" -->\n",
    "L'exactitude n'est pas la métrique à utiliser lorsque vous travaillez avec un jeu de données déséquilibrées.\n",
    "Nous avons vu que c'est trompeur.\n",
    "\n",
    "D'autres métriques ont été conçues pour vous raconter une histoire plus véridique lorsque vous travaillez\n",
    "avec des classes déséquilibrées. En voici quelques-unes présentées dans le module sur les métriques de\n",
    "qualité en classification:\n",
    "\n",
    "- exactitude,\n",
    "- précision,\n",
    "- rappel,\n",
    "- mesure $F_1$ (ou F-score),\n",
    "- aire sous les courbes ROC et Précision-Rappel.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"5c3c8d0a\" -->\n",
    "## <a id=ré-échantillonner-le-jeu-de-données>Ré-échantillonner le jeu de données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"f4e7901e\" -->\n",
    "Il est également possible de modifier un jeu de données afin d'obtenir des classes plus équilibrées. Cela\n",
    "mène souvent à une amélioration des performances en classification.\n",
    "\n",
    "Cette modification s'appelle le\n",
    "[ré-échantillonnage](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis).\n",
    "Il existe deux méthodes principales pour uniformiser les classes:\n",
    "- l'ajout de copies d'instances de la classe sous-représentée : suréchantillonnage (*oversampling*),\n",
    "- la suppression d'instances de la classe surreprésentée : sous-échantillonnage (*undersampling*).\n",
    "\n",
    "Ces approches sont souvent très faciles à mettre en œuvre et rapides à exécuter. Elles sont un excellent point de départ.\n",
    "\n",
    "En fait, il vaut mieux essayer les deux approches sur tous les jeux de données déséquilibrés, juste pour voir si cela donne une amélioration de vos mesures préférées.\n",
    "\n",
    "Voici quelques règles de base :\n",
    "- le sous-échantillonnage est préférable lorsque vous avez beaucoup de données (des dizaines, des centaines de milliers d'instances ou plus),\n",
    "- le suréchantillonnage est préférable lorsque vous n’avez pas beaucoup de données (des dizaines de milliers d’enregistrements ou moins),\n",
    "- tester différents ratios de rééchantillonnage (il n'est pas toujours nécessaire d'avoir un ratio de 1:1 dans un problème de classification binaire).\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"6401987b\" -->\n",
    "## <a id=générer-des-échantillons-synthétiques>Générer des échantillons synthétiques</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"17564c8c\" -->\n",
    "Il existe des algorithmes systématiques utilisables pour générer des échantillons synthétiques.\n",
    "Le plus populaire de ces algorithmes est appelé SMOTE ou technique de suréchantillonnage minoritaire synthétique.\n",
    "\n",
    "SMOTE est une méthode de suréchantillonnage. Elle fonctionne en créant de nouveaux échantillons synthétiques de\n",
    "la classe mineure au lieu d'en créer des copies.\n",
    "\n",
    "Il existe plusieurs implémentations de cet algorithme. La librairie Python\n",
    "[imbalanced-learn](https://imbalanced-learn.org/stable/user_guide.html) en fournit un certain nombre\n",
    "ainsi que diverses autres techniques de ré-échantillonnage.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"43ead402\" -->\n",
    "## <a id=essayer-les-modèles-pénalisés>Essayer les modèles pénalisés</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"c1ee898b\" -->\n",
    "La classification pénalisée impose un coût supplémentaire au modèle pour faire des erreurs de classification\n",
    "à la classe minoritaire pendant l'entraînement. Ces pénalités peuvent inciter le modèle à accorder plus\n",
    "d’attention à la classe minoritaire. C'est une approche utilisée dans les réseaux de neurones.\n",
    "\n",
    "Il existe des outils facilitant l'emploi de modèles pénalisés. Par exemple, Weka\n",
    "peut assigner à tout classificateur une matrice de pénalités personnalisée pour la classification des échecs.\n",
    "\n",
    "L’utilisation de la pénalisation est souhaitable si vous êtes restreints à un algorithme précis et êtes\n",
    "incapables de rééchantillonner ou si vous obtenez des résultats médiocres.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"e38ddf38-d027-4eae-95c8-749f8f40db43\" _uuid=\"1e287038acf96fc6d6825e77ba97b03f0824be0a\" colab_type=\"text\" id=\"5ce03805\" -->\n",
    "# <a id=exemples-de-ré-échantillonnage>Exemples de ré-échantillonnage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"b0bc04c4\" -->\n",
    "## <a id=lecture-dun-jeu-de-données-débalancé-contenant-deux-classes>Lecture d'un jeu de données déséquilibré contenant deux classes</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"5c3086b3\" -->\n",
    "Le jeu contient $100\\,000$ données de 20 variables, c'est-à-dire, $X=[x_{1}, \\cdots , x_{20}]$.\n",
    "La classe majoritaire (c.-à-d. la classe « 0 ») contient $99~\\%$ des données et la classe minoritaire (c.-à-d. la classe « 1 ») contient les $1~\\%$ restants.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ecb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/pax/shared/GIF-U014/dataset_debalance.csv\")\n",
    "y = df[\"target\"]\n",
    "X = df.drop(\"target\", axis=1).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ec075",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d46974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'un histogramme des valeurs de la réponse $y$\n",
    "\n",
    "target_count = df.target.value_counts()\n",
    "print(\"Classe 0:\", target_count[0])\n",
    "print(\"Classe 1:\", target_count[1])\n",
    "print(\"Proportion:\", round(target_count[0] / target_count[1], 4), \": 1\")\n",
    "ax = df.target.value_counts().plot(kind=\"bar\", title=\"Count (target)\", rot=0)\n",
    "ax.set_xlabel(\"Classe\", fontsize=15)\n",
    "ax.set_ylabel(\"N\", fontsize=15, rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b666d3b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"c91f9c5d-05d2-478e-9dfb-1cb848bc0fe4\" _uuid=\"8683656d1bfdef6b5c0c623597dcbc4160a0edc1\" colab_type=\"text\" id=\"07ffc549\" -->\n",
    "## <a id=le-piège-des-métriques>Le piège des métriques</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a411ea48\" -->\n",
    "L'un des principaux problèmes auxquels se heurtent les utilisateurs novices lorsqu'ils traitent des jeux\n",
    "de données déséquilibrés est lié aux métriques utilisées pour évaluer leur modèle. Utiliser des métriques\n",
    "plus simples comme l'exactitude peut être trompeur. Dans un ensemble de données avec des\n",
    "classes très déséquilibrées, si le classificateur \"prédit\" toujours la classe la plus courante sans\n",
    "effectuer d'analyse des caractéristiques, il conservera une exactitude élevée, évidemment illusoire.\n",
    "\n",
    "Faisons cette expérience en utilisant une simple validation croisée sans modifier les caractéristiques. \n",
    "\n",
    "> À noter que les principes d'utilisation de la validation croisée sont présentés dans un des modules de la méthodologie.\n",
    "\n",
    "Dans ce qui suit, on ne normalise pas les données, car elles sont déjà toutes du même ordre de grandeur.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=seed\n",
    ")\n",
    "\n",
    "# Sélection du classificateur\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e319cc9",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"c46b98a7-d500-4911-a7b5-c8fc8fbed069\" _uuid=\"5b17ee8d3629cc346398e63269205e5b654cef80\" colab_type=\"text\" id=\"524fc8da\" -->\n",
    "Exécutons maintenant le même code, mais en n'utilisant qu'une seule caractéristique parmi les 20 que contient chaque donnée. Cela devrait considérablement réduire l'exactitude du classificateur puisqu'il y a une grande perte d'information permettant de séparer les nuages de points de chaque classe. Est-ce le cas?\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b24749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(X_train[:, 0:1], y_train)\n",
    "y_pred = model.predict(X_test[:, 0:1])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae734ce",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"68d4ffaf-4412-4ff3-a9cd-38bea195da3b\" _uuid=\"d9d8b57f458bdd107ae08b76b0008d80e0674d97\" colab_type=\"text\" id=\"66957cdb\" -->\n",
    "Comme nous pouvons le constater, le taux de précision élevé n’était qu’illusion. De cette manière, le choix de la métrique utilisée dans les jeux de données non équilibrés est extrêmement important.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"b27346eb-7bf3-4360-993a-fb91e62bb937\" _uuid=\"875f5ab3b5afcdaf3c7754ce957cb01fd32bf65c\" colab_type=\"text\" id=\"38045e63\" -->\n",
    "## <a id=techniques-de-bases-en-ré-échantillonage>Techniques de bases en ré-échantillonnage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"307de623\" -->\n",
    "Le ré-échantillonnage est une technique largement adoptée pour traiter les jeux de données très déséquilibrés.\n",
    "Cela consiste à retirer des échantillons de la classe majoritaire (sous-échantillonnage ou\n",
    "*undersampling*) ou à ajouter d'autres exemples dans la classe minoritaire (suréchantillonnage ou *oversampling*).\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"03d31a16-7b66-4096-88d7-d548db734390\" _uuid=\"2232ac0fb192a468486b400846f88913a36957e6\" colab_type=\"text\" id=\"64f722bd\" -->\n",
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"0df1a3f3-49ff-4ada-80f1-198bbbd79525\" _uuid=\"67e203e0919c818e871650ef194fe497df2d39b5\" colab_type=\"text\" id=\"80595c90\" -->\n",
    "Malgré l'avantage de l'équilibrage des classes, ces techniques ont aussi leurs faiblesses. La\n",
    "mise en œuvre la plus simple du suréchantillonnage consiste à dupliquer aléatoirement des données de la\n",
    "classe minoritaire, ce qui peut entraîner un surapprentissage (*overfitting*). Dans le\n",
    "sous-échantillonnage, la technique la plus simple consiste à supprimer aléatoirement des enregistrements\n",
    "de la classe majoritaire, ce qui entraîne nécessairement une perte d'information.\n",
    "\n",
    "Implémentons un exemple de base, qui utilise la méthode `DataFrame.sample` pour obtenir aléatoirement\n",
    "des échantillons de chaque classe:\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de valeurs par classe\n",
    "count_class_0, count_class_1 = df.target.value_counts()\n",
    "\n",
    "# Séparation des classes\n",
    "df_class_0 = df[df[\"target\"] == 0]\n",
    "df_class_1 = df[df[\"target\"] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789a749",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"152ea73a-aa23-4fd2-a3f5-1f55c69041ae\" _uuid=\"b765be76a182930feb650b01dd4d1de90501bbce\" colab_type=\"text\" id=\"9cfc781e\" -->\n",
    "### <a id=sous-échantillonnage-aléatoire>Sous-échantillonnage aléatoire</a>\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print(\"Sous-échantillonnage aléatoire:\")\n",
    "print(df_test_under.target.value_counts())\n",
    "\n",
    "ax = df_test_under.target.value_counts().plot(kind=\"bar\", title=\"Count (target)\", rot=0)\n",
    "ax.set_xlabel(\"Classe\", fontsize=15)\n",
    "ax.set_ylabel(\"N\", fontsize=15, rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f02743",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"be656d47-e529-4533-b975-cf6de072d959\" _uuid=\"17192fe8557463941e3abd4633b58ced0037721b\" colab_type=\"text\" id=\"79ffd335\" -->\n",
    "### <a id=suréchantillonnage-aléatoire>Suréchantillonnage aléatoire</a>\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ff1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print(\"Suréchantillonnage aléatoire:\")\n",
    "print(df_test_over.target.value_counts())\n",
    "\n",
    "ax = df_test_over.target.value_counts().plot(kind=\"bar\", title=\"Count (target)\", rot=0)\n",
    "ax.set_xlabel(\"Classe\", fontsize=15)\n",
    "ax.set_ylabel(\"N\", fontsize=15, rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37cdee",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"9fd90ddc-f2fc-487d-b177-0c540daf2eff\" _uuid=\"9672899d4029b71b72897927ce464d6d7427ce77\" colab_type=\"text\" id=\"2ca29e2a\" -->\n",
    "## <a id=techniques-plus-avancées-en-ré-échantillonage>Techniques plus avancées en ré-échantillonnage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e38187f2\" -->\n",
    "Un certain nombre de techniques de ré-échantillonnage plus sophistiquées ont été proposées dans la\n",
    "littérature scientifique.\n",
    "\n",
    "Par exemple, il est possible de regrouper les données de la classe majoritaire et d'effectuer le\n",
    "sous-échantillonnage en supprimant des données de chaque regroupement (*cluster*). On préserve\n",
    "ainsi la distribution multidimensionnelle des données tout en réduisant leur nombre.\n",
    "En suréchantillonnage, au lieu de créer des copies exactes des données de la classe de minorité,\n",
    "nous pouvons introduire de petites variations dans ces copies, créant ainsi des échantillons\n",
    "synthétiques plus divers.\n",
    "\n",
    "Appliquons certaines de ces techniques de ré-échantillonnage en utilisant la librairie Python\n",
    "[imbalanced-learn](https://imbalanced-learn.org/stable/auto_examples/index.html#general-examples/).\n",
    "Elle est compatible avec Scikit-learn et fait partie des projets contributeurs de Scikit-learn.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"5542beb4-6aee-401a-8bc0-2a522fbbe90b\" _uuid=\"ff93d1707c416178c010c125319220b785dca984\" colab_type=\"text\" id=\"93b42a56\" -->\n",
    "### <a id=génération-dun-nouveau-jeu-de-données>Génération d'un nouveau jeu de données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"b13eaa80\" -->\n",
    "Pour faciliter la visualisation, créons un nouveau jeu de données de taille réduite, toujours avec\n",
    "deux classes, et ne contenant plus que 100 données $X$ de 20 variables. Cette fois-ci, la répartition\n",
    "des classes est de ($90~\\%$, $10~\\%$).\n",
    "\n",
    "À nouveau, on ne normalise pas les données, car elles sont déjà toutes du même ordre de grandeur.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_classes=2,\n",
    "    class_sep=1.5,\n",
    "    weights=[0.9, 0.1],\n",
    "    n_informative=3,\n",
    "    n_redundant=1,\n",
    "    flip_y=0,\n",
    "    n_features=20,\n",
    "    n_clusters_per_class=1,\n",
    "    n_samples=100,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"target\"] = y\n",
    "ax = df.target.value_counts().plot(kind=\"bar\", title=\"Count (target)\", rot=0)\n",
    "ax.set_xlabel(\"Classe\", fontsize=15)\n",
    "ax.set_ylabel(\"N\", fontsize=15, rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd650c01",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"4de57657-3aed-4444-a609-318063391763\" _uuid=\"d348b114ec1594eeefa0a67aab8b54e5b9ee2bdf\" colab_type=\"text\" id=\"b18e6bf1\" -->\n",
    "Nous allons également créer une fonction de tracé, <code>plot_2d_space</code>, pour afficher la répartition des données.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add32c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_space(X, y, label=\"Classes\"):\n",
    "    colors = [\"#1F77B4\", \"#FF7F0E\"]\n",
    "    markers = [\"o\", \"s\"]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(X[y == l, 0], X[y == l, 1], c=c, label=l, marker=m, alpha=0.5)\n",
    "    ax.set_xlabel(\"$PCA_{1}$\", fontsize=15)\n",
    "    ax.set_ylabel(\"$PCA_{2}$\", fontsize=15)\n",
    "    plt.title(label)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296028ad",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"2c565bbc-39ed-45a2-8b3d-bc501e2510aa\" _uuid=\"aabc110dd8d1b36345df6aada1c59b864e48e8e6\" colab_type=\"text\" id=\"7cfbf177\" -->\n",
    "Étant donné que le jeu de données est en 20-D et que nos graphiques seront en 2-D, la taille du jeu de données est\n",
    "réduite au moyen de l'analyse en composantes principales (*PCA*). On n'utilise que les deux\n",
    "premières composantes principales.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "plot_2d_space(\n",
    "    X,\n",
    "    y,\n",
    "    \"Jeu de données non équilibré \\n (\\\n",
    "2 premières composantes principales)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea3950",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"c3c9a24f-3cd0-4c8d-8a4d-4403c4f1a641\" _uuid=\"0d7316b04837aa103003d667f63ecb05d43fc04e\" colab_type=\"text\" id=\"2d9db88c\" -->\n",
    "### <a id=sous-échantillonnage-aléatoire-avec-apprentissage-déséquilibré>Sous-échantillonnage aléatoire avec apprentissage déséquilibré</a>\n",
    "\n",
    "Réduire le nombre de données de la classe majoritaire n'est pas une bonne option dans cet exemple, car il ne reste que peu de données à utiliser par la suite.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "id_rus = rus.sample_indices_\n",
    "\n",
    "print(\"Indices retirés :\", id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, \"Sous-échantillonnage aléatoire\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadd6fc",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"c3c9a24f-3cd0-4c8d-8a4d-4403c4f1a641\" _uuid=\"0d7316b04837aa103003d667f63ecb05d43fc04e\" colab_type=\"text\" id=\"2d9db88c\" -->\n",
    "### <a id=suréchantillonnage-aléatoire-avec-apprentissage-déséquilibré>Suréchantillonnage aléatoire avec apprentissage déséquilibré</a>\n",
    "\n",
    "Augmenter le nombre de données de la classe minoritaires n'est pas une bonne option dans cet exemple, car il y a trop peu de données différentes.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7033e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print(X_ros.shape[0] - X.shape[0], \"nouveaux points aléatoires\")\n",
    "\n",
    "plot_2d_space(X_ros, y_ros, \"Suréchantillonnage aléatoire\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d4cab4",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"3156134f-539b-48b8-b9d0-64095fe50c1c\" _uuid=\"b3f9ac47a157d9096a626360408859b795299c24\" colab_type=\"text\" id=\"60e05b4b\" -->\n",
    "### <a id=sous-échantillonnage-avec-liens-tomek>Sous-échantillonnage avec liens Tomek</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4c3257c9\" -->\n",
    "Les liens Tomek sont des paires d'instances très proches, mais de classes opposées. La suppression des occurrences de la classe majoritaire de chaque paire augmente l'espace entre les deux classes, facilitant ainsi le processus de classification.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"f131f7e0-007d-406e-9e1c-db352d2d8433\" _uuid=\"85c01c0e6baa1b984585c1db34c5ab0315cbf8ff\" colab_type=\"text\" id=\"d686c797\" -->\n",
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/tomek.png?v=2)\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"45bf057b-369c-4f37-a5ac-7417ad79253d\" _uuid=\"733a86ccfaaabf701fb2d1f9997c732b19630df3\" colab_type=\"text\" id=\"cc8ec7ff\" -->\n",
    "Dans le code ci-dessous, nous utiliserons `sampling_strategy = 'majority'` pour ré-échantillonner la classe majoritaire.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks(sampling_strategy=\"majority\")\n",
    "X_tl, y_tl = tl.fit_resample(X, y)\n",
    "id_tl = tl.sample_indices_\n",
    "\n",
    "print(\"Indices retirés:\", id_tl)\n",
    "\n",
    "plot_2d_space(X_tl, y_tl, \" Sous-échantillonnage des liens Tomek\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b438d6",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"fef831bd-ecec-429c-aef2-5d51d1188820\" _uuid=\"b4e75fffe4c91afcd63705aa7bcb16b6fd9f6b1f\" colab_type=\"text\" id=\"a56a69b6\" -->\n",
    "### <a id=sous-échantillonnage-avec-centroïdes-de-regroupements>Sous-échantillonnage avec centroïdes de regroupements</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8519b43a\" -->\n",
    "Cette technique effectue un sous-échantillonnage en générant des centroïdes basés sur des méthodes\n",
    "de regroupement (*clustering methods*). Les données seront préalablement regroupées par similarité,\n",
    "afin de préserver les informations.\n",
    "\n",
    "Dans cet exemple, le dictionnaire `{0: 10}` pour le paramètre `sampling_strategy`, indique\n",
    "de préserver 10 éléments de la classe majoritaire (0) et conserver toutes les données de la classe minoritaire (1).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(sampling_strategy={0: 10})\n",
    "X_cc, y_cc = cc.fit_resample(X, y)\n",
    "\n",
    "plot_2d_space(X_cc, y_cc, \"Cluster Centroids under-sampling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9a60b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"78adb7b4-a7e1-4d10-9cc2-6bf6477c63df\" _uuid=\"b3741f5c14acdbd76e25725e2d73df5f2cb0a239\" colab_type=\"text\" id=\"b19a591d\" -->\n",
    "### <a id=suréchantillonnage-avec-smote>Suréchantillonnage avec SMOTE</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"902c694e\" -->\n",
    "SMOTE (*synthetic minority oversampling technique*) consiste à synthétiser des éléments pour\n",
    "la classe minoritaire, sur la base de ceux qui existent déjà. Cela fonctionne de manière aléatoire\n",
    "en sélectionnant un point de la classe minoritaire et en calculant les k-voisins les plus proches\n",
    "pour ce point (k-NN). Les points synthétiques sont ajoutés entre le point choisi et ses voisins.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"5162646f-da82-4877-b6d8-25a8be7f42e9\" _uuid=\"51697e21b7cdb4064dda18aa24e6ecf039b1132b\" colab_type=\"text\" id=\"81102cbc\" -->\n",
    " ![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png)\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"9c0a0d78-8427-437e-aa24-ffe2bd12edb2\" _uuid=\"9393851db694c178faf93615bf05addedf5d678b\" colab_type=\"text\" id=\"c6d4e26e\" -->\n",
    "Nous allons utiliser `sampling_strategy = 'minority'` pour ré-échantillonner la classe minoritaire.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "plot_2d_space(X_sm, y_sm, \"Suréchantillonnage SMOTE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13541b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region _cell_guid=\"20c3cdbb-a7c1-45a5-8dd9-84cff7d9af31\" _uuid=\"d7ebbeb741ad6469cb7ebbced3499acd3c49856a\" colab_type=\"text\" id=\"69e1afe4\" -->\n",
    "### <a id=suréchantillonnage-suivi-dun-sous-échantillonnage>Suréchantillonnage suivi d'un sous-échantillonnage</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"92988821\" -->\n",
    "Nous pouvons maintenant combiner le suréchantillonnage et le sous-échantillonnage, en utilisant les techniques de liens SMOTE et Tomek.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(sampling_strategy=\"auto\")\n",
    "X_smt, y_smt = smt.fit_resample(X, y)\n",
    "\n",
    "plot_2d_space(X_smt, y_smt, \"SMOTE + Tomek links\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2739c9",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"789b0f04\" -->\n",
    "# <a id=pour-en-savoir-plus>Pour en savoir plus</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region _cell_guid=\"28d4431f-bc32-4cf0-988e-9df412cc22c1\" _uuid=\"401bcb8e508e584feca3a34ecfb9de270fde951c\" colab_type=\"text\" id=\"4ea87a9d\" -->\n",
    "- [Documentation](https://imbalanced-learn.org/stable/user_guide.html) de la librairie *imbalanced-learn*:\n",
    "- [Chawla, Nitesh V., et al. \"SMOTE: synthetic minority over-sampling technique.\" Journal of artificial intelligence research 16 (2002)](http://export.arxiv.org/pdf/1106.1813)\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
