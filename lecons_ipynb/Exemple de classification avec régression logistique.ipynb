{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0a3775",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"db6af3ab\" -->\n",
    "# Table des matières\n",
    "- [Exemple de classification avec régression logistique](#exemple-de-classification-avec-régression-logistique)\n",
    "  - [Lecture et préparation des données](#lecture-et-préparation-des-données)\n",
    "      - [Lecture des données](#lecture-des-données)\n",
    "      - [Séparation des données en ensembles d'entraînement et de test](#séparation-des-données-en-ensembles-dentraînement-et-de-test)\n",
    "      - [Normalisation des données](#normalisation-des-données)\n",
    "  - [Entraînement d'un classificateur de type régression logistique](#entraînement-dun-classificateur-de-type-régression-logistique)\n",
    "      - [Sélection du type de classificateur.](#sélection-du-type-de-classificateur)\n",
    "      - [Entraînement du classificateur avec les données d'entraînement](#entraînement-du-classificateur-avec-les-données-dentraînement)\n",
    "      - [Normalisation des données de test](#normalisation-des-données-de-test)\n",
    "      - [Prédiction des classes pour l'ensemble de test](#prédiction-des-classes-pour-lensemble-de-test)\n",
    "      - [Affichage des statistiques de classification](#affichage-des-statistiques-de-classification)\n",
    "  - [Interprétation des résultats](#interprétation-des-résultats)\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"18d78b5d\" -->\n",
    "---\n",
    "# Exemple de classification avec régression logistique\n",
    "---\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"24bea696\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/penguins1.png\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://github.com/allisonhorst/penguins/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"769f9103\" -->\n",
    "Dans cette section, nous allons appliquer la régression logistique afin de classifier trois espèces de manchots\n",
    "(*penguins*) à partir de mensurations de becs. Puis, nous allons voir comment interpréter les résultats afin\n",
    "de leur donner un sens autrement que numérique. C'est un type d'application en apprentissage automatique\n",
    "couramment utilisée par les biologistes.\n",
    "\n",
    "Nous allons utiliser le  jeu de données [penguin](https://www.kaggle.com/parulpandey/penguin-dataset-the-new-iris)\n",
    "qui est disponible sur Scikit Learn.\n",
    "\n",
    "\n",
    "\n",
    "La régression logistique modélise la probabilité d'appartenance à la classe 1\n",
    "(plutôt qu'à la classe 0) comme suit\n",
    "\n",
    "$$p(1\\vert X, \\Theta) = {\\dfrac  {1}{1+e^{-(a_{0} + a_{1}x_{1} + \\cdots +  a_{N}x_{N})}}}$$\n",
    "où $\\Theta=\\{a_{0}, \\cdots, a_{N}\\}$ représente l'ensemble des paramètres du modèle et où les $x_{i}$ sont\n",
    " les variables, dans ce cas-ci, les mensurations de becs de manchots.\n",
    "\n",
    "Puisque nous avons trois classes (Adélie, Chinstrap, Gentoo), et non deux, on traite d'abord le problème\n",
    "comme trois problèmes indépendants:\n",
    "\n",
    "\n",
    "- problème 1: p(Adélie|X),\n",
    "- problème 2: p(Chinstrap|X),\n",
    "- problème 3: p(Gentoo|X).\n",
    "\n",
    "\n",
    "Puis, on sélectionne la classe ayant la plus grande probabilité. C'est l'approche \"un contre tous\"\n",
    "(*one-versus-all*). Cette opération est faite de façon transparente par la fonction\n",
    "__[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__\n",
    "dans la librairie Scikit-Learn. Pas besoin de faire trois classifications!\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Pour la reproductibilité des résultats\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc98b1b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"6a10fb38\" -->\n",
    "## Lecture et préparation des données\n",
    "\n",
    "Le  jeu de données contient sept variables (colonnes). La colonne 1 contient la\n",
    "réponse que l'on veut prédire, soit l'espèce de manchot. Les colonnes 2 à 7 contiennent les variables mesurées\n",
    "(quatre quantitatives et deux catégorielles).\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"48329652\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/penguin-culmen.png\"  width=\"400\" />\n",
    "    <div>\n",
    "    <font size=\"1.5\">Image Source: https://allisonhorst.github.io/palmerpenguins/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a3ac700f\" -->\n",
    "Les variables quantitatives correspondent à la longueur et à l'épaisseur du bec (*bill*), à la longueur des\n",
    "nageoires (*flipper*) et à la masse de chaque animal. Les variables catégorielles correpondent à l'île\n",
    "où habitent les animaux et leur sexe.\n",
    "\n",
    "#### Lecture des données\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2eeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du jeu de données en format CSV et écriture dans un DataFrame\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Affichage des cinq premières lignes du fichier.\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f697d4",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"743b66a9\" -->\n",
    "On peut faire les observations suivantes:\n",
    "\n",
    "\n",
    "- il y a quelques lignes contenant des valeurs manquantes (NaN),\n",
    "- les valeurs des facteurs quantitatifs couvrent différent ordres de grandeur.\n",
    "\n",
    "\n",
    "Élimination des lignes contenant des valeurs manquantes.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101609df",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3d2e41f4\" -->\n",
    "Nous allons également éliminer les variables suivantes afin de rendre la tâche plus difficile au classificateur:\n",
    "\n",
    "\n",
    "- sexe,\n",
    "- nom de l'île,\n",
    "- longueur des nageoires,\n",
    "- masse.\n",
    "\n",
    "\n",
    "En effet, l'ensemble des variables permet de distinguer les manchots presque parfaitement. C'est la raison\n",
    "pour laquelle elles ont été choisies par les biologistes.\n",
    "\n",
    "Élimination des colonnes non utilisées.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['island', 'sex', 'flipper_length_mm', 'body_mass_g'], inplace=True, axis=1)\n",
    "\n",
    "# Affichage des cinq premières lignes de la base de donnnées résultante\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7d93d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"ff0c5348\" -->\n",
    "#### Séparation des données en ensembles d'entraînement et de test\n",
    "\n",
    "Extraction des variables X et de la réponse y\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762319ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(df.columns[[0]], axis=1)\n",
    "y = df.drop(df.columns[[1, 2]], axis=1)\n",
    "\n",
    "# Liste des variables utilisées\n",
    "feature_list = list(X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5c5eb",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"55967f6e\" -->\n",
    "Génération des ensembles d'entraînement ($80~\\%$ des données) et de test ($20~\\%$ restants). On utilise un\n",
    "échantillonnage stratifié afin de respecter la distribution des espèces de manchots dans chaque ensemble.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, stratify=y, random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ba0d9",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"7a44e028\" -->\n",
    "#### Normalisation des données\n",
    "\n",
    "Les paramètres de la fonction de normalisation sont calculés à partir des données d'entraînement **uniquement**.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87897f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a58d8",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"cb337188\" -->\n",
    "## Entraînement d'un classificateur de type régression logistique\n",
    "\n",
    "#### Sélection du type de classificateur\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548779c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d1d8f153\" -->\n",
    "#### Entraînement du classificateur avec les données d'entraînement\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_s, np.array(y_train).ravel());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11a075",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"0d55667d\" -->\n",
    "#### Normalisation des données de test\n",
    "\n",
    "Afin de mesurer les performances du modèle avec l'ensemble de test, il faut d'abord normaliser ces nouvelles données\n",
    "avec la même transformation qui a été appliquée aux données d'entraînement.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ebd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_s = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4f628",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"2821eac1\" -->\n",
    "#### Prédiction des classes pour l'ensemble de test\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7459e06",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"84b0d35f\" -->\n",
    "#### Affichage des statistiques de classification\n",
    "\n",
    "Affichage du rapport sur les statistiques de classification pour obtenir une comparaison plus fine des performances en test.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed89a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d19cc5",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5c061bbc\" -->\n",
    "On obtient une exactitude (*accuracy*) de $96~\\%$. Ainsi $96~\\%$ des prédictions d'espèces de manchots sont correctes.\n",
    "\n",
    "On observe des F1-scores de $88~\\%$ à $100~\\%$; les manchots Chinstrap sont les plus difficiles à classifier.\n",
    "\n",
    "La précision et le rappel s'expliquent comme suit. Dans le cas de l'espèce Chinstrap, $100~\\%$ des prédictions Chinstrap étaient correctes. Par contre seulement $79~\\%$ des manchots Chinstrap ont été identifiés.\n",
    "\n",
    "Comment expliquer cette différence entre précision et rappel? Le classificateur reconnait les manchots Chinstrap les plus faciles à identifier. Il les classifie parfaitement; $100~\\%$ de ses précisions sont correctes. Par contre, il ne reconnait pas les manchots Chinstrap un peu atypiques (très jeunes? très vieux?). Il en oublie plusieurs; il ne peut identifier que $79~\\%$ de leur population. Cet exemple montre que les deux métriques de rappel et de précision sont complémentaires. Se fier uniquement à la précision est dangereux. Imaginez que vous avez conçu un détecteur de lions pour la maison et qu'il a une précision de $100~\\%$ et un rappel de $10~\\%$. À toutes les fois qu'il en détectera un, vous pourrez être certain que c'en est un. Par contre, le détecteur ne pourra détecter que $10~\\%$ des lions dans la maison!\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a633a79d\" -->\n",
    "## Interprétation des résultats\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4fc1e1bc\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/inspector-with-magnifying-glass.jpeg\"  width=\"200\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: http://clipart-library.com/clipart/1416328.htm</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1e39495f\" -->\n",
    "Nous avons conçu un bon classificateur. Voyons maintenant comment interpréter les paramètres des modèles.\n",
    "La probabilité d'appartenance à une espèce de manchot est\n",
    "\n",
    "$$p(\\text{1}\\vert X) = p(\\text{Espèce}\\vert x_{1}, x_{2}) = {\\dfrac  {1}{1+e^{-(a_{0} + a_{1}x_{1} + a_{2}x_{2})}}}$$\n",
    "\n",
    "On remarque que plus le terme $a_{1}x_{1} + a_{2}x_{2}$ dans l'équation est grand, plus la probabilité est grande.\n",
    "\n",
    "Affichons les valeurs des $a_{i}$ pour chaque espèce de manchot.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients des modèles: \\t %s \\t %s \\n\" % (feature_list[0], feature_list[1]))\n",
    "for i, espèce in enumerate(clf.classes_):\n",
    "    print(\n",
    "        \"\\t Espèce: %s \\t a_{1} = %0.2f \\t\\t a_{2} = %0.2f\\n\"\n",
    "        % (espèce, clf.coef_[i][0], clf.coef_[i][1])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d213b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"cd78a86c\" -->\n",
    "On remarque que pour les manchots Adélie, $a_{1}<0$ et $a_{2}>0$. Le terme $a_{1}x_{1}+a_{2}x_{2}$\n",
    "devient maximal pour une petite valeur de $x_{1}$ et une grande valeur de $x_{2}$. Il est donc plus\n",
    "probable d'observer un manchot Adélie avec un bec trapu (court et épais).\n",
    "\n",
    "C'est l'inverse pour les manchots Gentoo, $a_{1}>0$ et $a_{2}<0$. Le terme $a_{1}x_{1}+a_{2}x_{2}$\n",
    "devient maximal pour une grande valeur de $x_{1}$ et une petite valeur de $x_{2}$. Il est donc plus probable\n",
    "d'observer un manchot Gentoo avec un bec effilé (long et mince).\n",
    "\n",
    "Finalement, les manchots Chinstrap ont $a_{1}>0$ et $a_{2}>0$. Il est donc plus probable\n",
    "de les observer avec un bec long et épais.\n",
    "\n",
    "C'est bien ce que l'on observe dans la figure suivante.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9df7ac16\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/penguins2.jpeg\" width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://www.pulseheadlines.com/climate-change-is-directly-affecting-the-penguin-population/27828/</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"76825aac\" -->\n",
    "Dans ce module, on a réussi à classifier les différentes espèces de manchots en plus d'expliquer les critères de\n",
    "classification. Le classificateur n'est pas une boîte noire que les biologistes doivent utiliser. Au contraire, ses\n",
    "critères de classification sont facilement compréhensibles en plus de montrer l'importance des variables\n",
    "mesurées sur le terrain.\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
