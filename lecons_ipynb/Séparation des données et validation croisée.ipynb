{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77090ac",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"66cf1ca3\" -->\n",
    "# Table des matières\n",
    "1. [Séparer ses données en combien d'ensembles?](#séparer-ses-données-en-combien-densembles)\n",
    "    1. [Un ensemble d'entraînement?](#un-ensemble-dentraînement)\n",
    "    1. [Un ensemble d'entraînement et un de validation?](#un-ensemble-dentraînement-et-un-de-validation)\n",
    "    1. [Un ensemble d'entraînement, un de validation, et un de test?](#un-ensemble-dentraînement-un-de-validation-et-un-de-test)\n",
    "1. [Principes de la validation croisée](#principes-de-la-validation-croisée)\n",
    "  1. [Entraînement d'un classificateur](#entraînement-dun-classificateur)\n",
    "    1. [Raison 1](#raison-1)\n",
    "    1. [Raison 2](#raison-2)\n",
    "    1. [Raison 3](#raison-3)\n",
    "  1. [Entraînement de multiples classificateurs et sélection du meilleur](#entraînement-de-multiples-classificateurs-et-sélection-du-meilleur)\n",
    "1. [Un exemple](#un-exemple)\n",
    "  1. [Lecture et préparation des données](#lecture-et-préparation-des-données)\n",
    "      1. [Balancement des classes](#balancement-des-classes)\n",
    "      1. [Normalisation des données](#normalisation-des-données)\n",
    "  1. [Classification par forêt aléatoire en utilisant les paramètres par défaut](#classification-par-forêt-aléatoire-en-utilisant-les-paramètres-par-défaut)\n",
    "  1. [Optimisation des hyperparamètres du classificateur par forêt aléatoire](#optimisation-des-hyperparamètres-du-classificateur-par-forêt-aléatoire)\n",
    "1. [Comment choisir son modèle final?](#comment-choisir-son-modèle-final)\n",
    "    1. [Optimisation sur grille et affichage des résultats](#optimisation-sur-grille-et-affichage-des-résultats)\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202aaf37",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"4f442694\" -->\n",
    "Dans ce module, nous allons discuter de l'importance de la séparation des données lors d'un projet\n",
    "en apprentissage automatique. La validation croisée est une méthode particulièrement efficace qui implémente cette idée.\n",
    "\n",
    "Nous allons montrer comment la validation croisée peut être utilisée afin d'optimiser les performances des algorithmes\n",
    "de traitement de données (régression, classification, etc.) Nous allons toutefois nous limiter\n",
    "aux applications en classification dans ce module. Nous allons également montrer comment utiliser la validation croisée\n",
    "pour faire la sélection de modèles. C'est-à-dire, pour choisir le meilleur parmi plusieurs classificateurs disponibles.\n",
    "Cela est très utile, car il existe au moins une dizaine de familles de classificateurs, dont chacune a ses variantes.\n",
    "\n",
    "> À noter que les résultats numériques affichés pour le classificateur de type forêt aléatoire peuvent varier d'une\n",
    "> exécution du tutoriel à la suivante. Toutefois, les conclusions que l'on tire des résultats affichés demeurent les mêmes.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"703a5642\" -->\n",
    "# <a id=séparer-ses-données-en-combien-densembles>Séparer ses données en combien d'ensembles?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"bfc952aa\" -->\n",
    "Imaginons qu'un professeur veuille faire passer un examen à ses étudiants. Pour les entraînements, il leur fournit\n",
    "une liste de 100 problèmes à résoudre avec la solution connue. Il prévoit les tester en leur posant 10 questions.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"fb5953ec\" -->\n",
    "## <a id=un-ensemble-dentraînement>Un ensemble d'entraînement?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"d57facd4\" -->\n",
    "Dans ce cas-ci, les étudiants s'entraînent avec la liste et sont testés avec 10 questions de la même liste. S'ils\n",
    "ont bien mémorisé la série de questions-réponses, ils peuvent avoir $100~\\%$ à l'examen; pas\n",
    "besoin de comprendre la matière du cours. C'est du surapprentissage.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"176eb22c\" -->\n",
    "## <a id=un-ensemble-dentraînement-et-un-de-validation>Un ensemble d'entraînement et un de validation?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"bb4af0ef\" -->\n",
    "Dans ce cas-ci, les étudiants s'entraînent avec la liste et sont testés avec 10 nouvelles questions\n",
    "qu'ils n'ont jamais vues. Seuls ceux qui ont compris la matière avec la liste d'entraînement\n",
    "passeront l'étape de validation. Peu probable qu'ils atteignent le $100~\\%$. Cette étape nous assure qu'ils savent\n",
    "résoudre des problèmes.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"a6365452\" -->\n",
    "## <a id=un-ensemble-dentraînement-un-de-validation-et-un-de-test>Un ensemble d'entraînement, un de validation, et un de test?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4d94e5ce\" -->\n",
    "Lequel parmi les étudiants ayant complété l'étape précédente est le meilleur? Plusieurs étudiants ont\n",
    "des résultats assez similaires. Se pourrait-il que les 10 questions du professeur aient été biaisées d'une manière\n",
    "ou d'une autre (style d'enseignement particulier?), ce qui aurait affecté les résultats du test? On demande alors\n",
    "à un autre professeur enseignant la même matière de fournir un dernier ensemble de nouvelles questions,\n",
    "de même niveau, afin de sélectionner le meilleur étudiant. Cette approche est utilisée afin d'évaluer les\n",
    "performances d'un grand nombre d'étudiants au niveau provincial plutôt que local.\n",
    "\n",
    "En résumé:\n",
    "\n",
    "- deux ensembles de données sont nécessaires pour bien entraîner un modèle,\n",
    "- mais trois ensembles sont nécessaires pour bien entraîner **et** sélectionner le meilleur modèle.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ef01fc84\" -->\n",
    "# <a id=principes-de-la-validation-croisée>Principes de la validation croisée</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"651d7946\" -->\n",
    "Nous allons voir comment l'utiliser pour entraîner un ou plusieurs modèles, afin de sélectionner le meilleur d'entre eux.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9c90f3f5\" -->\n",
    "## <a id=entraînement-dun-classificateur>Entraînement d'un classificateur</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"eb838600\" -->\n",
    "La figure suivante montre l'approche couramment utilisée pour l'entraînement d'un modèle. Cet exemple utilise\n",
    "une validation croisée à cinq plis (*Folds*); le nombre de plis pourrait être différent.\n",
    "\n",
    "On sépare initialement\n",
    "les données en un ensemble d'entraînement (*Training Dataset*) et un autre de test (*Testing Dataset*).\n",
    "Puis l'ensemble d'entraînement est subdivisé à son tour en plusieurs séries de plis. Par convention, dans chaque pli, les données en bleu\n",
    "correspondent à l'ensemble de validation, et les données en vert à l'ensemble d'entraînement.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9087f399\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/training-folds.png\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://tex.stackexchange.com/questions/492892/drawing-three-tables-with-tikz/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<p>&nbsp;</p>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"595dc6cd\" -->\n",
    "Les données d'entraînement sont utilisées pour estimer les valeurs des paramètres\n",
    "d'un classificateur. Les données de test sont utilisées pour calculer la métrique\n",
    "finale (exactitude, précision, rappel, etc.) du classificateur sur de nouvelles données jamais vues par le classifieur.\n",
    "\n",
    "Pourquoi utiliser des plis pour l’entraînement du modèle? Il y a au moins trois bonnes raisons à cela.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"02c047a7\" -->\n",
    "### <a id=raison-1>Raison 1</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"36af7dfe\" -->\n",
    "Il arrive que le nombre de données d'entraînement soit limité.\n",
    "Si l'on sépare l'ensemble d'entraînement en $80~\\%$ train et $20~\\%$ validation, on obtient une valeur de métrique pouvant être affectée par le faible nombre de données. Il est préférable d'utiliser cinq échantillonnages\n",
    "différents comme sur la figure précédente, puis d’entraîner et tester le modèle sur chacun d’entre eux. En\n",
    "faisant la moyenne des cinq valeurs de métrique, on obtient une meilleure estimation de celle-ci.\n",
    "De plus, les cinq plis sont bien séparés. Cela veut dire que le modèle a été entraîné et testé cinq fois avec des données différentes à chaque fois. Cela favorise la généralisation du modèle pour de nouvelles données.\n",
    "Une métrique moyenne, plus précise, permet de mieux optimiser\n",
    "les paramètres du modèle entraîné.\n",
    "\n",
    "Pourquoi ne pas utiliser la métrique moyenne comme valeur finale? La raison est simple. Bien que les\n",
    "cinq plis soient bien séparés, chaque donnée est utilisée dans quatre entraînements. Il est donc possible\n",
    "que cette surutilisation des mêmes données ait un effet sur le résultat final. C'est pourquoi on évalue les\n",
    "performances finales avec l'ensemble de test qui contient de nouvelles données.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"d1738a83\" -->\n",
    "### <a id=raison-2>Raison 2</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"020e04e1\" -->\n",
    "En calculant l'écart-type des cinq valeurs de métrique, on obtient aussi une mesure de la robustesse de la\n",
    "prédiction. Par exemple, un classificateur qui obtient un score moyen de $90~\\%$ avec un écart-type de $7~\\%$,\n",
    "est moins fiable qu'un autre qui obtient un score de $89~\\%$ avec un écart-type de $1~\\%$. Contrairement\n",
    "aux librairies R et SAS qui sont utilisées en statistiques, les fonctions de la librairie Scikit-learn ne fournissent pas les erreurs et les intervalles de confiances associés aux métriques calculées. Toutefois, la validation croisée permet de les estimer en analysant les valeurs générées par les plis. Ce n'est pas une faiblesse de Scikit-learn. Cette librairie a été conçue pour l’entraînement des modèles et la prédiction, pas pour faire de l'analyse statistique des paramètres. Ceci est plutôt la spécialité de logiciels comme R et SAS. Les buts sont différents, voilà tout.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"09ec53a0\" -->\n",
    "### <a id=raison-3>Raison 3</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"657f63a4\" -->\n",
    "La validation croisée gère mieux le problème des classes déséquilibrées. Supposons que l'ensemble d'entraînement\n",
    "contienne 100 valeurs dont 10 appartiennent à la classe minoritaire. Séparer l'ensemble\n",
    "d'entraînement en $80~\\%$ train et $20~\\%$ validation fera en sorte que l'ensemble de validation devrait contenir\n",
    "en moyenne deux items de la classe minoritaire ($20~\\%$ de 10 items). Il est probable qu'il n'y en ait qu'un ou même aucun. La mesure de la métrique de performance du classificateur serait trop imprécise. En utilisant cinq plis de $20~\\%$ plutôt qu'un seul et en faisant la moyenne des résultats, on obtient une estimation plus réaliste de la métrique.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"71e5d2e7\" -->\n",
    "## <a id=entraînement-de-multiples-classificateurs-et-sélection-du-meilleur>Entraînement de multiples classificateurs et sélection du meilleur</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"c6e0787e\" -->\n",
    "La figure suivante montre l'approche couramment utilisée pour faire de la sélection de modèles. Chaque\n",
    "modèle est entraîné comme précédemment avec les mêmes données d'entraînement. Le meilleur modèle est sélectionné selon la moyenne des résultats en validation croisée. Sa métrique de performance est ensuite\n",
    "mesurée avec l'ensemble de test.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9e987f01\" -->\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/k-fold-cross-validation.jpeg\"  width=\"700\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://www.javierorraca.com/posts/2020-02-01-k-fold-cross-validation/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"d77d9563\" -->\n",
    "# <a id=un-exemple>Un exemple</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"54295aaa\" -->\n",
    "## <a id=lecture-et-préparation-des-données>Lecture et préparation des données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"2fcd2ac0\" -->\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/matrix-data-exchange.jpeg\"  width=\"350\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://pixabay.com/illustrations/matrix-network-data-exchange-1027571/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"31750fc8\" -->\n",
    "Nous allons nous servir du jeu de données sur le diabète utilisées dans un module précédent portant sur la classification par forêt aléatoire. \n",
    "Le jeu de données contient neuf variables (colonnes), la dernière Outcome contient la réponse binaire que l'on veut prédire, soit le sujet est atteint du diabète (« `'Outcome=1'` ») ou non (« `'Outcome=0'` »).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0594dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/pax/shared/GIF-U014/diabetes_nettoyée.csv\")\n",
    "\n",
    "X = df.drop([\"Outcome\"], axis=1)\n",
    "y = df.Outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba4c958",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"27a8a9ca\" -->\n",
    "### <a id=balancement-des-classes>Balancement des classes</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"08ef9d0e\" -->\n",
    "Les classes sont-elles balancées? Affichons le nombre de données pour chacune.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04349ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind=\"bar\").set_title(\"Diabetes Outcome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66c6be",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"2ce2ddf5\" -->\n",
    "La classe 0 comprend environ $65~\\%$ des données; il y a un léger débalancement des données. Nous allons utiliser la\n",
    "méthode d'imputation SMOTE afin d'éliminer ce déséquilibre. Le nombre d'éléments de la classe 1 sera augmenté\n",
    "afin d'égaliser de la classe 0.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf55625",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d136c2d7\" -->\n",
    "Affichons à nouveau le nombre de données pour chaque classe.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55280c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm.value_counts().plot(kind=\"bar\").set_title(\"Diabetes Outcome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252e392",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"045037b6\" -->\n",
    "Les classes sont maintenant balancées.\n",
    "\n",
    "Générons les ensembles de données d'entraînement et de test. On utilise un\n",
    "échantillonnage stratifié afin qu'il y ait les mêmes proportions de classes dans les deux ensembles.\n",
    "Les données seront réparties comme suit: train ($80~\\%$) et test ($20~\\%$).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f705867",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sm, y_sm, test_size=0.2, shuffle=True, stratify=y_sm, random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816136cb",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"1da818f8\" -->\n",
    "### <a id=normalisation-des-données>Normalisation des données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e91f051b\" -->\n",
    "Les paramètres de la fonction de normalisation doivent être calculés à partir des données\n",
    "d'entraînement uniquement. La même fonction est ensuite appliquée aux deux ensembles de données.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409668df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1b085",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d8badfc7\" -->\n",
    "## <a id=classification-par-forêt-aléatoire-en-utilisant-les-paramètres-par-défaut>Classification par forêt aléatoire en utilisant les paramètres par défaut</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"2cefe227\" -->\n",
    "Dans ce premier exemple, on entraîne le classificateur tel quel. C'est-à-dire, sans ajuster ses hyperparamètres\n",
    "afin de maximiser ses performances en classification.\n",
    "\n",
    "Chaque entraînement produira cinq valeurs de la métrique de performance utilisée, dans ce cas-ci, l'exactitude.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179571a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "kf = KFold(n_splits=5)\n",
    "result = cross_val_score(rf, X_train_s, y_train, cv=kf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b931485",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitude pour chaque pli: {}\".format(result))\n",
    "print(\"Exactitude moyenne: %0.3f\" % (result.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5287c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5a13e452\" -->\n",
    "Selon ce résultat, le classificateur atteint une exactitude de $80,4~\\%$. Est-ce que l'apprentissage s'est bien passé?\n",
    "Y a-t-il surapprentissage? Pour le savoir on va prédire la réponse $y$ pour chaque ensemble de données, soit\n",
    "celui d'entraînement, dont le classificateur a vu les données, et celui de test dont il n'a jamais vu les données.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement avec toutes les données d'entraînement (sans pli)\n",
    "model = rf.fit(X_train_s, y_train)\n",
    "\n",
    "# Prédiction des réponses y pour chaque ensemble\n",
    "y_pred_train = model.predict(X_train_s)\n",
    "y_pred_test = model.predict(X_test_s)\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données d'entraînement: %0.1f %%\"\n",
    "    % (100 * accuracy_score(y_train, y_pred_train))\n",
    ")\n",
    "print(\n",
    "    \"Exactitude sur les données de test: %0.1f %%\"\n",
    "    % (100 * accuracy_score(y_test, y_pred_test))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ca3c3",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"b7f74ace\" -->\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/man-pointing-silhouette.jpeg\"  width=\"200\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://publicdomainpictures.net/en/view-image.php?image=74319&picture=man-pointing-silhouette&large=1</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"491ab678\" -->\n",
    "L'exactitude de $100~\\%$ pour les données d'entraînement montre que le classificateur les a mémorisées;\n",
    "il y a surapprentissage. D'ailleurs, la grande différence entre les deux résultats ($82~\\%$ *versus* $100~\\%$) est\n",
    "un indicateur de surapprentissage.\n",
    "\n",
    "Cela montre que les valeurs par défaut des classificateurs ne sont pas toujours les meilleures.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1d02c818\" -->\n",
    "## <a id=optimisation-des-hyperparamètres-du-classificateur-par-forêt-aléatoire>Optimisation des hyperparamètres du classificateur par forêt aléatoire</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"2dd11b29\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/target-idea.jpeg\"  width=\"350\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://www.wallpaperflare.com/target-business-idea-growth-business-idea-concept-planning-wallpaper-aoydx</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0e396051\" -->\n",
    "Quelles sont les valeurs des hyperparamètres permettant d'obtenir les meilleures performances en classification?\n",
    "Pour le découvrir, nous allons effectuer une série d'entraînements en utilisant des hyperparamètres répartis\n",
    "aux extrémités d'une grille de recherche. Un classificateur sera entraîné pour chaque point sur la grille et\n",
    "le classificateur optimal sera déterminé en sélectionnant le meilleur parmi eux. Chaque hyperparamètre est\n",
    "un « bouton » que l'on peut ajuster afin d'optimiser le résultat final. Le nombre de possibilités\n",
    "augmente rapidement avec le nombre d'hyperparamètres.\n",
    "\n",
    "Dans ce qui suit, nous allons nous concentrer sur trois d'entre eux:\n",
    "\n",
    "- `n_estimators`,\n",
    "- `max_depth`,\n",
    "- `criterion`.\n",
    "\n",
    "\n",
    "Le nombre total de combinaisons d'hyperparamètres est de $3 x 3 x 3 = 27$.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7734b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [125, 150, 175],\n",
    "    \"max_depth\": [1, 3, 5],\n",
    "    \"min_samples_split\": [2, 3, 4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf84379",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"684b6c8c\" -->\n",
    "Pour chaque ensemble d'hyperparamètres sur la grille de recherche, un classificateur sera entraîné et\n",
    "ses performances seront évaluées en utilisant une validation croisée à cinq plis. Puisque chaque\n",
    "modèle sera entraîné cinq fois, un total de $5 x 27 = 135$ modèles seront entraînés.\n",
    "\n",
    "Puisque les classes sont maintenant balancées, chaque classificateur sera entraîné afin de maximiser l'exactitude (*Accuracy*).\n",
    "\n",
    "> À noter que la fonction `GridSearchCV` assigne les hyperparamètres optimaux au classificateur de départ lorsque *refit=True*.\n",
    "Ainsi, après avoir entraîné chaque modèle et isolé le meilleur, celui-ci est réentraîné en utilisant l'ensemble des données d'entraînement (c.-à-d. sans validation croisée).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    "    scoring=\"accuracy\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef0124",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement de tous les modèles sur la grille d'hyperparamètres\n",
    "\n",
    "grid_search.fit(X_train_s, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f34bc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du meilleur choix d'hyperparamètres\n",
    "\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df145ab",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3cbe8c0f\" -->\n",
    "Refaisons le test précédent pour vérifier s'il y a surapprentissage. On doit prédire la réponse y en utilisant toutes les données d'entraînement et de test.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour l'ensemble d'entraînement\n",
    "pred_train = grid_search.predict(X_train_s)\n",
    "\n",
    "# Prédictions pour l'ensemble de test\n",
    "pred_test = grid_search.predict(X_test_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65212198",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f23a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des valeurs d'exactitude pour les deux ensembles\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données d'entraînement: %0.1f %%\"\n",
    "    % (100 * accuracy_score(y_train, pred_train))\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données de test: %0.1f %%\\n\\n\"\n",
    "    % (100 * accuracy_score(y_test, pred_test))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a174910",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"9238f182\" -->\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/man-pointing-silhouette.jpeg\"  width=\"200\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://publicdomainpictures.net/en/view-image.php?image=74319&picture=man-pointing-silhouette&large=1</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"7b566a73\" -->\n",
    "Il n'y a plus de surapprentissage puisque les deux valeurs d'exactitude sont rapprochées et inférieures à $100~\\%$!\n",
    "De plus, l'exactitude sur les données de test ($81,0~\\%$) est assez près de celle de $82,0~\\%$ mesurée \n",
    "dans la section précédente.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0cde5830\" -->\n",
    "Le rapport de classification fournit une comparaison plus fine des performances en test.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9287948",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"e97aceea\" -->\n",
    "On obtient une exactitude (*Accuracy*) de $81~\\%$. Ainsi $81~\\%$ des prédictions (sujets avec ou sans diabète) sont correctes.\n",
    "\n",
    "La précision est la proportion des résultats positifs qui correspondent réellement à des sujets diabétiques: $76\\%$.\n",
    "\n",
    "Le rappel (*Recall*) est la proportion des sujets diabétiques détectés : $90~\\%$.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e4eedf43\" -->\n",
    "# <a id=comment-choisir-son-modèle-final>Comment choisir son modèle final?</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9aa18315\" -->\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/model-choice.jpeg\"  width=\"700\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://www.javierorraca.com/posts/2020-02-01-k-fold-cross-validation/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"dda154ab\" -->\n",
    "Le classificateur par forêt aléatoire est-il le meilleur? Il est utile de comparer plusieurs classificateurs\n",
    "entre eux et de choisir le meilleur. En pratique, on le fait souvent pour une dizaine de classificateurs ou plus.\n",
    "\n",
    "Dans ce qui suit, nous allons comparer deux classificateurs; la forêt aléatoire et la régression logistique.\n",
    "\n",
    "Liste des classificateurs à comparer:\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1fefa",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5ee826c6\" -->\n",
    "Liste des grilles de paramètres pour chacun. Dans cet exemple, on va réutiliser les\n",
    "paramètres optimaux pour la forêt aléatoire. Toutefois, rien n'empêche d'utiliser la grille\n",
    "de recherche précédente et refaire l'optimisation.\n",
    "\n",
    "La classe `LogisticRegression` a deux importants paramètres à optimiser. Soit la méthode de régularisation\n",
    "et le paramètre de régularisation mentionné dans le module sur la régularisation.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7157af",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = grid_search.best_params_\n",
    "rf_param_grid = dict(map(lambda item: (item[0], [item[1]]), best.items()))\n",
    "\n",
    "lr_param_grid = {\"penalty\": [\"none\", \"l2\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "param_grid = {\"Random Forest\": rf_param_grid, \"LogisticRegression\": lr_param_grid}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f588d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"fa2dfcfb\" -->\n",
    "## <a id=optimisation-sur-grille-et-affichage-des-résultats>Optimisation sur grille et affichage des résultats</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"26b57ac7\" -->\n",
    "Pour chaque classificateur, on affiche les valeurs d'exactitudes en entraînement et en test afin de déterminer s'il est en surapprentissage. Lorsque c'est le cas, il faut affiner les grilles de paramètres correspondantes.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "head = list(classifiers.items())\n",
    "best_model = []\n",
    "for name, clf in head:\n",
    "    params = param_grid[name]\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=params,\n",
    "        cv=5,\n",
    "        refit=True,\n",
    "        n_jobs=2,\n",
    "        verbose=2,\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "    grid_search.fit(X_train_s, y_train)\n",
    "\n",
    "    score_train = grid_search.score(X_train_s, y_train)\n",
    "    score_test = grid_search.score(X_test_s, y_test)\n",
    "\n",
    "    best_model.append(grid_search)\n",
    "    print(\"{:<15}:\".format(name))\n",
    "    print(\n",
    "        \"\\tExactitude sur les données d'entraînement : %0.1f %%\" % (100 * score_train)\n",
    "    )\n",
    "    print(\"\\tExactitude sur les données de test : %0.1f %%\" % (100 * score_test))\n",
    "\n",
    "    print(\"\\tParamètres optimaux: %s\\n\" % str(grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cadb4d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"ae87ac54\" -->\n",
    "Le meilleur classificateur demeure la forêt aléatoire avec une exactitude de $81,0~\\%$.\n",
    "\n",
    "Notez qu'aucun des classificateurs n’est en surapprentissage puisque les valeurs d'exactitudes en entraînement\n",
    "et en test sont similaires et qu'aucune valeur n’atteint $100~\\%$.\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
