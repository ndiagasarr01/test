{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a719603",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    formats: md,ipynb\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"549d9fb9\" -->\n",
    "# Table des matières\n",
    "1. [La culture de l'expérimentation](#la-culture-de-lexpérimentation)\n",
    "1. [Le b.a.-ba des méthodes de projections](#le-b.a.-ba-des-méthodes-de-projections)\n",
    "1. [Exemples de méthodes de réduction de la dimensionnalité](#exemples-de-méthodes-de-réduction-de-la-dimensionnalité)\n",
    "  1. [Lecture et affichage des données](#lecture-et-affichage-des-données)\n",
    "  1. [Projection aléatoire](#projection-aléatoire)\n",
    "  1. [Analyse en composantes principales](#analyse-en-composantes-principales)\n",
    "  1. [Analyse par discriminants linéaires](#analyse-par-discriminants-linéaires)\n",
    "  1. [Isomap](#isomap)\n",
    "  1. [Encodage localement linéaire](#encodage-localement-linéaire)\n",
    "  1. [Échelonnage multidimensionnel métrique](#échelonnage-multidimensionnel-métrique)\n",
    "  1. [Encodage spectral](#encodage-spectral)\n",
    "  1. [*T-Distributed Stochastic Neighbor Embedding*](#it-distributed-stochastic-neighbor-embeddingi)\n",
    "1. [Applications](#applications)\n",
    "  1. [Déroulement d'un rouleau suisse](#déroulement-dun-rouleau-suisse)\n",
    "  1. [Aplatissement d'une sphère manquant un quartier](#aplatissement-dune-sphère-manquant-un-quartier)\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "from sklearn import (\n",
    "    manifold,\n",
    "    datasets,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    discriminant_analysis,\n",
    "    random_projection,\n",
    ")\n",
    "from sklearn.decomposition import FastICA\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "Axes3D\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f41514",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d8ea47b9\" -->\n",
    "La réduction de la dimensionnalité consiste à prendre des données dans un espace de grande dimension, et à les\n",
    "transformer en données dans un espace de plus petite dimension. Le défi consiste à conserver le maximum d’information\n",
    "partagée entre les données lors de la transformation. Ainsi, les données en sortie, plus petites, pourront\n",
    "être traitées plus rapidement et plus efficacement avec nos algorithmes d’analyse et de traitement.\n",
    "Les applications sont multiples en classification, régression et regroupement des données (*Data Clustering*).\n",
    "\n",
    "Une des raisons pour lesquelles la réduction de la dimensionnalité est si importante est liée au fait\n",
    "que les algorithmes performent mal avec des données en haute dimension. Le problème est connu sous le nom du\n",
    "[fléau de la dimension](https://fr.wikipedia.org/wiki/Fléau_de_la_dimension#:~:text=Le_fléau_de_la_dimension_ou_malédiction_de,pas_lieu_dans_des_espaces_dimension_moindre.)\n",
    " (*Curse of Dimensionnality*).\n",
    "\n",
    "On ne peut pas simplement enlever plusieurs des dimensions d'un ensemble de données afin de réduire la dimension\n",
    "finale de celles-ci. La figure suivante montre ce qu'il arrive lorsqu'on projette une surface 3-D sur une surface 2-D en éliminant une composante à la fois. Chaque objet en bois se transforme en différentes lettres selon la direction de projection! Il y a beaucoup d'information perdue à chaque fois qu'on élimine une des dimensions.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"127a1ffc\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/godel-escher-bach.jpeg\"  width=\"250\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://emergentbydesign.com/2012/04/16/what-are-the-most-life-changing-books-youve-read-twitter-poll//</font>\n",
    "    </div>\n",
    "</div>\n",
    "<p>&nbsp;</p>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"92adbb6b\" -->\n",
    "Plusieurs méthodes de réduction de la dimensionnalité procèdent de façon plus astucieuse. On transforme d'abord\n",
    "l'ensemble de données initial $X=[x_{1}, \\cdots, x_{N}]$ en un nouvel ensemble $Y=[y_{1}, \\cdots, y_{N}]$ où\n",
    "la majorité de l'information est contenue dans les premières composantes; $y_{1}, y_{2}$ par exemple. Idéalement,\n",
    "les points voisins dans l'espace de départ devraient rester voisins dans l'espace d'arrivée. Puis, on ne garde que les $M$ premières composantes du vecteur transformé, soit $Y=[y_{1}, \\cdots, y_{M}]$ avec $M<<N$. La valeur de $M$ est déterminée  selon la méthode utilisée.\n",
    "\n",
    "Le panneau gauche de la figure suivante montre un exemple 3-D où les données occupent les trois dimensions, mais sont\n",
    "regroupées sur une surface de plus petite dimension (*Manifold*), dans ce cas-ci un plan. Le panneau de droite\n",
    "montre le résultat de la réduction de la dimensionnalité. Dans cet exemple, on a utilisé\n",
    "l'[analyse en composantes principales (ACP)](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales) \n",
    "pour transformer les données. C'est une des méthodes présentées dans ce module. Notez comme\n",
    "le bruit dans les données a été réduit en passant de 3-D en 2-D; cela faciliterait\n",
    "par exemple la classification des quatre nuages de points.\n",
    "\n",
    "Les méthodes précédentes sont linéaires; elles projettent les données d'un espace N-D vers un autre espace N-D, plus pratique, puis en extraient un sous-ensemble de $M$ variables. Les méthodes non linéaires sont encore plus astucieuses. Elles transforment directement un espace N-D en un autre M-D avec $M<<N$; ce n'est pas une projection, mais plutôt un plongement (*Data Embedding*). Les deux types de méthodes sont présentés dans le module.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"103f39a5\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/pca-illustration.png\"  width=\"700\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: http://phdthesis-bioinformatics-maxplanckinstitute-molecularplantphys.matthias-scholz.de/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"c0b0befb\" -->\n",
    "# <a id=la-culture-de-lexpérimentation>La culture de l'expérimentation</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"828072db\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/baby-lego.jpeg\"  width=\"250\" />                                                       <div>\n",
    "    <font size=\"0.5\">Image Source: https://p1.pxfuel.com/preview/632/789/181/baby-lego-boy-constructor.jpg/</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"e1ff1032\" -->\n",
    "On présente dans ce module plusieurs méthodes de réduction de la dimensionnalité sans explications\n",
    "(PCA, MDS, T-SNE, etc.). On les introduit uniquement comme méthodes possibles à essayer. Elles sont\n",
    "populaires et très utilisées en analyse des données. Expliquer ici chacune d’entre elles serait\n",
    "trop long. Si vous voulez en savoir plus, nous vous invitons à lire à leur sujet en consultant par\n",
    "exemple la documentation de Scikit-learn.\n",
    "\n",
    "En pratique, on essaie souvent plusieurs méthodes pour solutionner un problème. Celles qui fonctionnent\n",
    "bien sont ensuite analysées plus à fond. Pas besoin, dans un premier temps, de connaitre la théorie\n",
    "derrière chaque méthode possiblement intéressante. C’est un peu l’idée de Scikit-learn qui montre plein\n",
    "de démos utiles. On essaie celles qui semblent prometteuses et on approfondit ensuite celles qu’on\n",
    "a finalement décidé d’utiliser.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"2afbd2c6\" -->\n",
    "# <a id=le-b.a.-ba-des-méthodes-de-projections>Le b.a.-ba des méthodes de projections</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"944b3168\" -->\n",
    "Dans la section suivante, nous allons utiliser la réduction de la dimensionnalité afin de regrouper\n",
    "ensemble des images similaires de dimension 8x8. C'est une application simple qui permet de bien comprendre l'idée\n",
    "derrière la méthode.\n",
    "\n",
    "Supposons que nous avons un ensemble d'images telles que chacune correspond à un point dans un espace de\n",
    "dimension $8\\times8=64$. Il est évidemment impossible de visualiser la distribution des images sous cette forme.\n",
    "On peut toutefois réduire la dimensionnalité de l'espace afin de le projeter dans un sous-espace de dimension 2. C'est\n",
    "nettement plus pratique!\n",
    "\n",
    "Parler de projeter une image dans un espace 2-D (deux dimensions) est évidemment un abus de langage.\n",
    "Cela veut simplement dire que pour chaque image, prenons celle d'un 4 par exemple, on transforme ses coordonnées de\n",
    "64-D à 2-D, puis on affiche le symbole 4 à la position 2-D dans le plan. On ne s'intéresse\n",
    "pas à une déformation quelconque de l'image du 4, mais uniquement à sa position finale dans l'espace d'arrivée en 2-D.\n",
    "\n",
    "Il existe de nombreuses méthodes de projection produisant des résultats souvent\n",
    "très différents. Nous allons en décrire plusieurs. Idéalement, les chiffres similaires\n",
    "devraient tous être regroupés ensemble, sans superposition avec d'autres chiffres, dans le plan 2-D.\n",
    "\n",
    "Plusieurs des méthodes sont linéaires et d'autres sont non linéaires. Qu'est-ce que ça veut dire? Commençons\n",
    "par les méthodes linéaires. Transformons une image, par exemple le chiffre 4 précédent, en\n",
    "un vecteur $X$ en 64-D. Une projection linéaire transformera le vecteur $X$ en un nouveau vecteur $Y$ en 64-D\n",
    "selon\n",
    "\n",
    "$$\\bf{y} =  \\bf{M} \\bf{x}$$\n",
    "avec\n",
    "\n",
    "$$\\bf{M} = \\begin{pmatrix} m_{1,1} & m_{1,2} & \\cdots & x_{1,64} \\\\\n",
    "\\vdots & &  &   \\vdots \\\\\n",
    "m_{64,1} & x_{64,2} & \\cdots & x_{64,64} &  \\end{pmatrix},\n",
    "\\bf{x} =\\begin{pmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{64}  \\end{pmatrix},\n",
    "     \\bf{y} =\\begin{pmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{64}  \\end{pmatrix}.$$\n",
    "L'étape suivante consiste à ne garder que les deux premières valeurs du vecteur transformé $Y$. L'affichage des\n",
    "points $(y_{1},y_{2})$ dans le plan produira plusieurs des figures qui suivent. Pour chaque méthode de réduction de\n",
    "dimensionnalité, le secret de la sauce est dans les coefficients de la matrice de transformation $M$.\n",
    "\n",
    "Les méthodes non linéaires ne sont pas basées sur des combinaisons\n",
    "linéaires des composantes $x_{i}$. Elles sont plus complexes et généralement itératives. C'est-à-dire, qu'il n'existe pas de\n",
    "relation simple entre les composantes $x_{i}$ et $y_{i}$. Difficile d'être plus simple sans aller dans les détails.\n",
    "\n",
    "Les méthodes linéaires ont été les premières utilisées, car on peut les dériver analytiquement. Les méthodes\n",
    "non linéaires, généralement plus performantes, ont émergé des travaux\n",
    "sur les réseaux de neurones et ont été mises en pratique grâce à la puissance de calcul des ordinateurs.\n",
    "\n",
    "Plusieurs méthodes sont présentées dans ce qui suit. Les méthodes linéaires sont présentées en premier.\n",
    "Les méthodes non linéaires suivent ensuite. Elles donnent généralement de\n",
    "meilleurs résultats que les premières, mais sont plus gourmandes en mémoire et temps de calcul.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8e8dc267\" -->\n",
    "# <a id=exemples-de-méthodes-de-réduction-de-la-dimensionnalité>Exemples de méthodes de réduction de la dimensionnalité</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"5b85ee64\" -->\n",
    "Cette partie est inspirée des\n",
    "[exemples de code](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py)\n",
    "de la librairie Scikit-learn.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"38feb164\" -->\n",
    "### <a id=lecture-et-affichage-des-données>Lecture et affichage des données</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ca2d21f6\" -->\n",
    "Nous allons utiliser un sous-ensemble du jeu de données\n",
    "[**MNIST**](https://en.wikipedia.org/wiki/MNIST_database)\n",
    "qui comprend des images de chiffres 0 à 9 de taille $8 \\text{ par } 8$. Les images du jeu de données original sont de taille $28 \\text{ par } 28$. Nous allons n'utiliser que les images des chiffres 0 à 5.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54507e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30\n",
    "n_components = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcedc74",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region colab_type=\"text\" id=\"2afbd2c6\" -->\n",
    "Exemples d'images de chiffres 0 à 5.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix : ix + 8, iy : iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Une sélection des 6 premiers chiffres du jeu de données MNIST');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04f9bb",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"38feb164\" -->\n",
    "Le code ci-dessous sert à afficher les graphiques pour les exemples de projection qui suivent.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(\n",
    "            X[i, 0],\n",
    "            X[i, 1],\n",
    "            str(y[i]),\n",
    "            color=plt.cm.Set1((y[i] + 1) / 10.0),\n",
    "            fontdict={'weight': 'bold', 'size': 9},\n",
    "        )\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf55c29",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region colab_type=\"text\" id=\"0cfcd114\" -->\n",
    "## <a id=projection-aléatoire>Projection aléatoire</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"c743755b\" -->\n",
    "Cette méthode effectue une projection des chiffres au moyen d'une matrice aléatoire clairsemée (*Sparse Random Matrix*).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rp = random_projection.SparseRandomProjection(\n",
    "    n_components=n_components, random_state=seed\n",
    ")\n",
    "X_projected = rp.fit_transform(X)\n",
    "plot_embedding(X_projected, \"Projection aléatoire des chiffres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1f048",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5a451fb7\" -->\n",
    "Les résultats ne sont pas particulièrement convaincants puisqu'on observe un grand recouvrement des \n",
    "classes de chiffres; la séparation des images 0 à 5 est inefficace.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"6a7be59a\" -->\n",
    "## <a id=analyse-en-composantes-principales>Analyse en composantes principales</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4dccd501\" -->\n",
    "L'analyse en composantes principales (*Principal Components Analysis* ou *PCA*) est une méthode linéaire classique qui consiste à transformer des variables $x_i$ corrélées entre elles (c.-à-d. liées) en nouvelles variables $y_i$ décorrélées les unes des autres. Les nouvelles variables sont nommées « composantes principales ». Elles sont ordonnées en ordre décroissant d'importance (mesurée par leur variance) selon\n",
    "\n",
    "$$\\sigma^2(y_1)>\\sigma^2(y_2)>\\cdots \\sigma^2(y_{N})$$\n",
    "\n",
    "Lorsqu'on veut compresser un ensemble de $N$ variables aléatoires, les $M$ premiers axes de l'analyse en composantes principales sont un meilleur choix, du point de vue de la variance.\n",
    "\n",
    "La figure suivante montre les deux premiers axes principaux.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0faa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_pca = decomposition.PCA(n_components=n_components).fit_transform(X)\n",
    "plot_embedding(X_pca, \"Projection des chiffres en composantes principales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f812db",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"9ace3a71\" -->\n",
    "La séparation des classes de chiffres est meilleure que pour la projection aléatoire.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"1883db4e\" -->\n",
    "## <a id=analyse-par-discriminants-linéaires>Analyse par discriminants linéaires</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8930322e\" -->\n",
    "L'analyse par discriminants linéaires (*Linear Discriminant Analysis* ou *LDA*) est une méthode linéaire qui projette les chiffres au moyen des deux principaux discriminants linéaires. La transformation utilise à la fois les positions des données et leurs étiquettes. Elle surpasse la PCA lorsqu'il y a beaucoup de données, autrement la PCA est à privilégier.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X2 = X.copy()\n",
    "X2.flat[:: X.shape[1] + 1] += 0.01  # X doit être inversable ...\n",
    "X_lda = discriminant_analysis.LinearDiscriminantAnalysis(\n",
    "    n_components=n_components\n",
    ").fit_transform(X2, y)\n",
    "plot_embedding(X_lda, \"Projection des chiffres par discrimination linéaire\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b244d6",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"90d78728\" -->\n",
    "Les regroupements observés sont les meilleurs jusqu'à maintenant.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"52fe5db8\" -->\n",
    "## <a id=isomap>Isomap</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8c5324fc\" -->\n",
    "Cette méthode et les suivantes sont toutes non linéaires.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6564bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_iso = manifold.Isomap(\n",
    "    n_neighbors=n_neighbors, n_components=n_components\n",
    ").fit_transform(X)\n",
    "plot_embedding(X_iso, \"Projection des chiffres par Isomap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4893b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region colab_type=\"text\" id=\"df6a54d6\" -->\n",
    "## <a id=encodage-localement-linéaire>Encodage localement linéaire</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"d62c240a\" -->\n",
    "Si on aime jouer avec les mots, on peut dire qu'une méthode localement linéaire est globalement non linéaire.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = manifold.LocallyLinearEmbedding(\n",
    "    n_neighbors=n_neighbors, n_components=n_components, method='standard'\n",
    ")\n",
    "X_lle = clf.fit_transform(X)\n",
    "plot_embedding(X_lle, \"Encodage localement linéaire des chiffres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1634a",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"554511ca\" -->\n",
    "Pas très convaincant dans ce cas-ci...\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"d44e01f0\" -->\n",
    "## <a id=échelonnage-multidimensionnel-métrique>Échelonnage multidimensionnel métrique</a>\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = manifold.MDS(n_components=n_components, n_init=1, max_iter=100)\n",
    "X_mds = clf.fit_transform(X)\n",
    "plot_embedding(X_mds, \"Encodage MDS des chiffres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c35e2",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"ea81db6a\" -->\n",
    "Les classes sont assez bien séparées, mais ont une grande dispersion interne.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"6ecd38a5\" -->\n",
    "## <a id=encodage-spectral>Encodage spectral</a>\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedder = manifold.SpectralEmbedding(\n",
    "    n_components=n_components, random_state=0, eigen_solver=\"arpack\"\n",
    ")\n",
    "X_se = embedder.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_se, \"Encodage spectral des chiffres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97973c8",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"d99b06d5\" -->\n",
    "Les résultats suivants ne sont pas facilement interprétables, bien que les chiffres soient relativement bien séparés.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab_type=\"text\" id=\"f492f4cd\" -->\n",
    "# <a id=it-distributed-stochastic-neighbor-embeddingi>*T-Distributed Stochastic Neighbor Embedding*</a>\n",
    "Cette méthode est souvent connu sous le nom t-SNE.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_tsne, \"Encodage t-SNE des chiffres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5533d2",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"0dd64ba8\" -->\n",
    "C'est la meilleure avec ce jeu de données. Non seulement les classes sont bien séparées, mais elles ont une faible\n",
    "dispersion interne; les nuages de points sont compacts. C'est une des méthodes les plus populaires\n",
    "en ce moment. La séparation est rarement parfaite, mais elle est souvent meilleure que\n",
    "celles obtenues avec les autres méthodes.\n",
    "\n",
    "Regardez le site suivant pour une présentation de la méthode\n",
    "[t-SNE](https://github.com/oreillymedia/t-SNE-tutorial) avec animation.\n",
    "\n",
    "> À noter que la méthode t-SNE peut afficher des liens différents selon les hyperparamètres utilisés. Cela veut dire que les résultats observés peuvent changer; les regroupements peuvent être moins bien séparés et même se superposer partiellement.\n",
    "Regardez-le [site suivant](https://distill.pub/2016/misread-tsne/) pour en savoir plus sur les forces et les faiblesses de la méthode.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region colab={} colab_type=\"code\" id=\"4ecc1c90\" -->\n",
    "# <a id=applications>Applications</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"df6283f0\" -->\n",
    "Une application surprenante de la réduction de la dimensionnalité est l'aplatissement ou le déroulement\n",
    "d'une surface 3-D sur une surface 2-D, par exemple sur une table. Nous allons en voir deux exemples.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1ed38c62\" -->\n",
    "Le code ci-dessous sert à afficher les graphiques.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31160a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DerouleSurface3D(X, colors, n_neighbors=10):\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    fig.suptitle(\n",
    "        \"Déroulement ou aplatissement de surface 3D avec \\\n",
    "                 %i points, %i voisins\"\n",
    "        % (X.shape[0], n_neighbors),\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Affiche la surface 3 D de départ\n",
    "    ax = fig.add_subplot(231, projection='3d')\n",
    "    ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=colors, cmap=plt.cm.Spectral)\n",
    "    ax.view_init(4, -72)\n",
    "\n",
    "    # Méthodes de réduction de dimensionnalité utilisées pour effectuer le\n",
    "    # déroulement de la surface sur un plan.\n",
    "    LLE = partial(\n",
    "        manifold.LocallyLinearEmbedding,\n",
    "        n_components=2,\n",
    "        n_neighbors=n_neighbors,\n",
    "        eigen_solver='auto',\n",
    "    )\n",
    "\n",
    "    methods = OrderedDict()\n",
    "    methods['Encodage localement linéaire'] = LLE(method='standard')\n",
    "    methods['Isomap'] = manifold.Isomap(n_components=2, n_neighbors=n_neighbors)\n",
    "    methods['MDS'] = manifold.MDS(n_components=2, max_iter=100, n_init=1)\n",
    "    methods['Encodage spectral'] = manifold.SpectralEmbedding(\n",
    "        n_components=2, n_neighbors=n_neighbors\n",
    "    )\n",
    "    methods['t-SNE'] = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "\n",
    "    # Affiche le résultat du déroulement pour chaque méthode\n",
    "    for i, (label, method) in enumerate(methods.items()):\n",
    "        t0 = time()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            Y = method.fit_transform(X)\n",
    "        t1 = time()\n",
    "        print(\"%s: %.2g sec\" % (label, t1 - t0))\n",
    "        ax = fig.add_subplot(2, 3, 2 + i)\n",
    "        ax.scatter(Y[:, 0], Y[:, 1], c=colors, cmap=plt.cm.Spectral)\n",
    "        ax.set_title(\"%s\" % (label))\n",
    "        ax.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax.yaxis.set_major_formatter(NullFormatter())\n",
    "        ax.axis('tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43497e8e",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"62180a35\" -->\n",
    "## <a id=déroulement-dun-rouleau-suisse>Déroulement d'un rouleau suisse</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"fb278b60\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/vesuvius-scrolls.jpeg\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://allthatsinteresting.com/virtually-unravel-vesuvius-scrolls/</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"f36f3b0d\" -->\n",
    "Voici une application de la réduction de dimensionnalité en archéologie. On utilise cette approche parmi\n",
    "d'autres, pour dérouler des rouleaux de papyrus carbonisés! Un grand nombre d'entre eux ont\n",
    "été trouvés dans une bibliothèque de la ville d'Herculanum détruite lors de l'éruption du Vésuve, en Italie,\n",
    "en 79 A.D. Ils ont été imagés dans un scanneur CT (à rayons X) et on peut voir l'encre disposée en rouleau suisse\n",
    "dans sa matrice carbonisée! On peut isoler les positions 3-D des zones d'encre puis utiliser plusieurs des\n",
    "méthodes précédentes afin de projeter les zones d'encre en 2-D; on peut alors lire un papyrus carbonisé\n",
    "il y a près de 2 000 ans! Comme dans bien des choses, le principe est simple, mais les détails sont complexes. Regardez la\n",
    "[vidéo](https://youtu.be/PpNq2cFotyY) suivante pour vous donner une idée des défis à relever.\n",
    "\n",
    "La figure suivante montre les résultats du déroulement du rouleau suisse obtenus en utilisant cinq des\n",
    "méthodes présentées dans la première section. Le premier panneau montre la surface de départ et les autres\n",
    "montrent les résultats du déroulement. Le code de couleur identifie les points voisins avant et après chaque\n",
    "transformation. Un bon déroulement de la surface devrait conserver l'agencement local des couleurs.\n",
    "\n",
    "Cet exemple s'inspire d'un exemple de code de la librairie\n",
    "[Scikit-learn](https://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py).\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1000\n",
    "n_neighbors = 10\n",
    "\n",
    "# Génération du rouleau suisse\n",
    "X, couleurs = datasets.make_swiss_roll(n_points)\n",
    "\n",
    "DerouleSurface3D(X, couleurs, n_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec54e",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3073a9e2\" -->\n",
    "La méthode Isomap produit les meilleurs résultats. Notez que la méthode t-SNE, qui marchait si bien\n",
    "dans la section précédente, déchire la bande en plusieurs sections.\n",
    "\n",
    "La méthode Isomap devrait permettre de lire quelques sections d'un papyrus déroulé.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"1133a714\" -->\n",
    "## <a id=aplatissement-dune-sphère-manquant-un-quartier>Aplatissement d'une sphère manquant un quartier</a>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4af03e52\" -->\n",
    "À première vue, ça semble impossible à faire. Toutefois, il ne faut pas oublier que les méthodes de réduction de\n",
    "dimensionnalité peuvent tordre les objets, comme on l'a vu dans l'exemple précédent. L'exemple qui suit\n",
    "s'inspire d'un exemple de code de la librairie\n",
    "[Scikit-learn](https://scikit-learn.org/stable/auto_examples/manifold/plot_manifold_sphere.html#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py/).\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 2000\n",
    "n_neighbors = 30\n",
    "\n",
    "# Génération d'une sphère manquant un quartier\n",
    "random_state = check_random_state(0)\n",
    "phi = random_state.rand(n_points) * (1.5 * np.pi)\n",
    "theta = random_state.rand(n_points) * np.pi\n",
    "\n",
    "x, y, z = np.sin(theta) * np.cos(phi), np.sin(theta) * np.sin(phi), np.cos(theta)\n",
    "\n",
    "X = np.array([x, y, z]).T\n",
    "couleurs = phi\n",
    "\n",
    "DerouleSurface3D(X, couleurs, n_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc598e7",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"28b5f947\" -->\n",
    "Toutes les méthodes, sauf t-SNE qui la déchire, réussissent à déformer localement la sphère 3-D afin\n",
    "de la déplier sur un plan! C'est un exercice de topologie facile à réaliser.\n",
    "\n",
    "Pensez-y un instant. Ces méthodes utilisent uniquement les notions de voisinage pour déformer des\n",
    "surfaces complexes. Aucun modèle analytique de sphère ou de rouleau suisse n'est utilisé, sauf\n",
    "pour générer les données initiales.\n",
    "\n",
    "Libre à vous d'explorer de nouvelles formes (non fermées) à déformer!\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
