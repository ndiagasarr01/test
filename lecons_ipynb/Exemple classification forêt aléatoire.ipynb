{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7664939",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"bd6d5a06\" -->\n",
    "# Table des matières\n",
    "- [Exemple de classification par forêt aléatoire](#exemple-de-classification-par-forêt-aléatoire)\n",
    "  - [Lecture et préparation des données](#lecture-et-préparation-des-données)\n",
    "      - [Lecture du jeu de données en format CSV](#lecture-de-la-base-de-données-en-format-csv)\n",
    "      - [Affichage de statistiques sur les données](#affichage-de-statistiques-sur-les-données)\n",
    "      - [Élimination d'une colonne inutile](#élimination-dune-colonne-inutile)\n",
    "      - [Séparation des variables X et de la réponse y du jeu de données.](#séparation-des-variables-x-et-de-la-réponse-y-de-la-base-de-données)\n",
    "      - [Vérification du débalancement des classes](#vérification-du-débalancement-des-classes)\n",
    "      - [Génération stratifiée des ensembles d'entraînement ($80~\\%$ des données) et de test ($20~\\%$ restants)](#génération-stratifiée-des-ensembles-dentraînement-80-des-données-et-de-test-20-restants)\n",
    "      - [Normalisation des données](#normalisation-des-données)\n",
    "  - [Question](#question)\n",
    "  - [Entraînement d'un classificateur de type forêt aléatoire](#entraînement-dun-classificateur-de-type-forêt-aléatoire)\n",
    "      - [Sélection du classificateur](#sélection-du-classificateur)\n",
    "      - [Entraînement du classificateur avec les données d'entraînement](#entraînement-du-classificateur-avec-les-données-dentraînement)\n",
    "  - [Affichage des statistiques de classification](#affichage-des-statistiques-de-classification)\n",
    "      - [Prédictions pour les ensembles d'entraînement et de test](#prédictions-pour-les-ensembles-dentraînement-et-de-test)\n",
    "      - [Comparaison des valeurs d'exactitude](#comparaison-des-valeurs-dexactitude)\n",
    "      - [Affichage du rapport sur les statistiques de classification](#affichage-du-rapport-sur-les-statistiques-de-classification)\n",
    "  - [Identification des variables les plus importantes pour diagnostiquer le diabète](#identification-des-variables-les-plus-importantes-pour-diagnostiquer-le-diabète)\n",
    "      - [Calcul de l'importance de chaque variable.](#calcul-de-limportance-de-chaque-variable)\n",
    "    - [Affichage du diagrame d'importance, ou du spectre d'importance, des variables du jeu de données](#affichage-du-diagrame-dimportance-ou-du-spectre-dimportance-des-variables-de-la-base-de-données)\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"aa9a3c2f\" -->\n",
    "---\n",
    "# Exemple de classification par forêt aléatoire\n",
    "---\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"f83e124a\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/diabetes-blood-sample.jpeg\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: https://medicalfitness.com.au/type-1-and-2-diabetes-australia/</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"4a5eb103\" -->\n",
    "Dans cette section, nous allons appliquer la classification par forêt aléatoire afin de prédire si un patient\n",
    "est diabétique ou non en fonction de variables mesurés à la suite d'une visite médicale typique (prise\n",
    "de pression, de sang, d'urine, de poids, etc.)\n",
    "\n",
    "Ce type d'analyse a mené à une meilleure compréhension du diabète. C'est un bel exemple de l'utilisation de\n",
    "l'apprentissage automatique en médecine. Dans ce problème, nous sommes confrontés à des données\n",
    "disparates (taux de glucose dans le sang, indice de masse corporelle, épaisseur de la peau, etc.)\n",
    "\n",
    "Comme on l'a vu dans les précédentes sections, la classification sert à prédire une *réponse* $y$, qui est\n",
    "une variable ordinale ou catégorique (c.-à-d. une classe), en fonction de plusieurs variables $x_{i}$\n",
    "\n",
    "$$y=f(x_{1}, \\cdots, x_{N}, \\Theta)$$\n",
    "\n",
    "où $\\Theta$ représente l'ensemble des paramètres de la fonction $f$.\n",
    "\n",
    "Il est généralement impossible de modéliser exactement cette fonction dû au grand nombre de phénomènes\n",
    "impliqués lors de la prise de données. La modélisation par forêt aléatoire permet de passer outre à la\n",
    "modélisation analytique. Elle permet de modéliser un phénomène impliquant un très grand nombre d'interactions entre les\n",
    "différentes variables sans avoir à les spécifier explicitement dans un modèle mathématique. C'est une des raisons\n",
    "qui expliquent leur immense champ d'applications en sciences de la vie et en sciences sociales par exemple.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Pour la reproductibilité des résultats\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da3e6",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"8aadf220\" -->\n",
    "## Lecture et préparation des données\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"b856da26\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/classifier-model.png\"  width=\"500\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: Google Image</font>\n",
    "    </div>\n",
    "</div>\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"7897e110\" -->\n",
    "Le  jeu de données contient neuf variables, continues ou ordinales, qui ont été mesurées chez 768 sujets:\n",
    "\n",
    "\n",
    "- Pregnancies: nombre de grossesses,\n",
    "- Glucose: taux de glucose,\n",
    "- BloodPressure: pression artérielle,\n",
    "- SkinThickness: épaisseur de la peau,\n",
    "- Insulin: taux d'insuline,\n",
    "- BMI: indice de masse corporelle (IMC), \n",
    "- DiabetesPedigreeFunction: facteur de diabète,\n",
    "- Age: âge,\n",
    "- Outcome: résultat.\n",
    "\n",
    "\n",
    "La dernière, Outcome, contient la réponse binaire que l'on veut prédire. Le patient est atteint\n",
    "du diabète lorsque Outcome=1.\n",
    "\n",
    "Les données originales ont été extraites du jeu de données\n",
    "[diabetes](https://www.kaggle.com/uciml/pima-indians-diabetes-database). Celle-ci contient toutefois\n",
    "plusieurs valeurs manquantes. Elle a été nettoyée en remplaçant, pour chaque variable sauf Pregnancies et Outcome, les valeurs manquantes par la valeur médiane des valeurs présentes. Dans ce qui suit, nous allons utiliser les données nettoyées.\n",
    "\n",
    "Le but de notre analyse est de déterminer si un sujet est diabétique, ou non, en fonction de ces variables.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"dc7ea12a\" -->\n",
    "#### Lecture du jeu de données en format CSV\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/pax/shared/GIF-U014/diabetes_nettoyée.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36adf77d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"661fa91b\" -->\n",
    "#### Affichage de statistiques sur les données\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e663f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e595b2",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"a0ffd894\" -->\n",
    "On voit que les valeurs couvrent différents ordres de grandeur. Il faudra les normaliser pour cette raison. Bien que les arbres décisionnels et les forêts aléatoires ne soient pas affectés par la normalisation, c'est une bonne habitude de normaliser ses données.\n",
    "\n",
    "#### Élimination d'une colonne inutile\n",
    "\n",
    "La colonne 'Unnamed: 0' contient un indice allant de 0 à 767. Elle est inutile.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('Unnamed: 0');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5261dfd",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"464e5c08\" -->\n",
    "On voit que les valeurs couvrent différents ordres de grandeur. Il faudra les normaliser pour cette raison. Bien que les arbres décisionnels et les forêts aléatoires ne soient pas affectés par la normalisation, c'est une bonne habitude de normaliser ses données.\n",
    "\n",
    "#### Séparation des variables X et de la réponse y du jeu de données\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Outcome'], axis=1)\n",
    "y = df.Outcome\n",
    "\n",
    "# Liste des variables utilisées\n",
    "feature_list = list(X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912499b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"89346c43\" -->\n",
    "#### Vérification du débalancement des classes\n",
    "\n",
    "Affichons le nombre de données pour chacune.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind='bar').set_title('Diabetes Outcome');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb5881",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"55662d08\" -->\n",
    "La classe 0 comprend environ $65~\\%$ des données. Il y a un léger débalancement des données dont nous allons tenir compte\n",
    "pour la suite de l'analyse.\n",
    "\n",
    "#### Génération stratifiée des ensembles d'entraînement ($80~\\%$ des données) et de test ($20~\\%$ restants)\n",
    "\n",
    "Les données d'entraînement vont servir à entraînement le classificateur. C'est-à-dire, à estimer la valeur du seuil  $\\tau$  de chaque noeud, dans chaque arbre décisionnel de la forêt. Les données de test vont ensuite servir à mesurer les performances du modèle entrainé à prédire correctement si une personne est atteinte ou non du diabète.\n",
    "\n",
    "L'échantillonnage stratifié fait en sorte que les deux ensembles de données contiennent les mêmes proportions de sujets diabétiques et sains.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65bda7",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"9815a089\" -->\n",
    "#### Normalisation des données\n",
    "\n",
    "Les paramètres de la fonction de normalisation doivent être calculés à partir des données\n",
    "d'entraînement **uniquement**. La même fonction est ensuite appliquée aux ensembles d'entraînement et de test. Il ne\n",
    "faut pas normaliser les données avant de générer les ensembles d'entraînement et de test.\n",
    "\n",
    "Selon la méthode StandardScaler, chaque colonne $x_i$ d'une matrice $X$ est transformée de la façon suivante\n",
    "\n",
    "$$x'_i = \\dfrac{x_i-\\mu_i}{\\sigma_i}$$\n",
    "\n",
    "où $\\mu_i$ et $\\sigma_i$ sont la moyenne et l'écart-type des valeurs de $x_i$ calculées avec les données d'**entraînement**.\n",
    "\n",
    "> À noter que les performances des arbres décisionnels et des forêts aléatoires ne sont pas affectées par la\n",
    "normalisation! On va quand même normaliser les données dans ce qui suit afin de montrer la bonne\n",
    "façon de procéder dans la pratique.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c303b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"107d9537\" -->\n",
    "## Question\n",
    "\n",
    "Pourquoi les paramètres de la fonction de normalisation doivent-ils être calculés uniquement à partir des données\n",
    "d'entraînement?\n",
    "\n",
    "**Réponse: Dans la pratique, on entraine un classificateur (ou un régresseur) après avoir fait subir\n",
    "toutes les étapes du prétraitement des données à l'ensemble d'entraînement. Plus tard, lorsque vient le moment de\n",
    "classifier de nouvelles données, celles-ci n'ont jamais été vues par le classificateur. Elles doivent subir\n",
    "à leur tour toutes les étapes du prétraitement. L'idée d'utiliser un ensemble de test est justement de simuler\n",
    "cette situation; il ne doit donc pas avoir participé à l'entraînement des fonctions de prétraitement\n",
    "des données telles que la normalisation.**\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"8260384f\" -->\n",
    "<a name=\"Entraînement\"></a>\n",
    "## Entraînement d'un classificateur de type forêt aléatoire\n",
    "\n",
    "#### Sélection du classificateur\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879672f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=4, min_samples_split=4, n_estimators=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96527efd",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"830cff94\" -->\n",
    "#### Entraînement du classificateur avec les données d'entraînement\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_s, y_train);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33bdb8",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"2c5266f0\" -->\n",
    "## Affichage des statistiques de classification\n",
    "\n",
    "Nous allons maintenant calculer quelques métriques pour évaluer les performances en classification. Celles-ci sont\n",
    "décrites dans le module sur les métriques de qualité en classification. Il est toutefois utile de les décrire ici brièvement afin de mieux comprendre nos résultats de classification:\n",
    "\n",
    "\n",
    "- exactitude (*accuracy*): C'est la fraction des prédictions (sujets avec ou sans diabète) qui se sont avérées exactes,\n",
    "- précision (*precision*): C'est la fraction des prédictions positives (sujets avec diabète) qui se sont avérées exactes,\n",
    "- rappel (*recall*): C'est la fraction des sujets positifs (avec diabète) qui ont été détectés,\n",
    "- score $F_1$: C'est la moyenne harmonique de la précision et du rappel. Il est défini comme suit.\n",
    "\n",
    "\n",
    "$$F_1=\\frac{2 *Précision *Rappel}{Précision + Rappel}$$\n",
    "\n",
    "Dans une situation où il est difficile de choisir entre les métriques $Précision$ et $Rappel$, le\n",
    "score $F_1$, qui les combine, est souvent préféré. Pourquoi ne pas simplement utiliser la moyenne arithmétique des deux métriques? Cela est dû au fait que chacune est un pourcentage et donc un ratio. On doit utiliser la moyenne harmonique\n",
    "pour calculer la moyenne de ratios.\n",
    "\n",
    "Voici un exemple. Supposons que la distance entre deux villes est de 120 km. À l'aller, le trajet dure 3 h et au retour il dure 2 h. La vitesse est de $v_a=40$ km/h à l'aller, et de $v_r=60$ km/h au retour. La vitesse moyenne est-elle réellement de $\\bar{v}=(v_a+v_b)/2=50$ km/h? Non! Une distance totale de 240 km a été parcourue en 5 h. La vitesse moyenne est de\n",
    "$\\bar{v} = 240 \\text{ km}/5\\text{ h}=48\\text{ km/h}$. La bonne réponse est la moyenne harmonique:\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "\\bar{v} &= \\frac{2 v_{a} v_{r}}{v_{a} +v_{r}} \\\\\n",
    "        &= \\frac{2 \\times 40 \\times 60 }{40 + 60} \\\\\n",
    "        &= 48\n",
    "\\end{align}$$\n",
    "\n",
    "La différence entre 48 km/h et 50 km/h n'est pas grande, mais elle est réelle.\n",
    "> À noter que l'on calcule souvent la moyenne arithmétique de pourcentages, qui sont des ratios. Ce n'est pas la bonne façon de procéder, mais c'est dans les habitudes.\n",
    "\n",
    "Comme vous le voyez, il y a des subtilités dans les définitions des différentes métriques, mais elles sont importantes.\n",
    "\n",
    "#### Prédictions pour les ensembles d'entraînement et de test\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(X_train_s)\n",
    "pred_test = clf.predict(X_test_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9ab1d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"2877532b\" -->\n",
    "#### Comparaison des valeurs d'exactitude\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Exactitude sur les données d'entraînement: %0.1f %%\"\n",
    "    % (100 * accuracy_score(y_train, pred_train))\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Exactitude sur les données de test: %0.1f %%\\n\"\n",
    "    % (100 * accuracy_score(y_test, pred_test))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4848234",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"1dc1bc77\" -->\n",
    "L'exactitude en entraînement est d'environ $83~\\%$ alors que celle en test est d'environ $73~\\%$.\n",
    "Ainsi $73~\\%$ des prédictions effectuées sur de nouveaux sujets, avec ou sans diabète, sont correctes.\n",
    "\n",
    "#### Affichage du rapport sur les statistiques de classification\n",
    "\n",
    "Celui-ci permet d'obtenir une comparaison plus fine des performances en test.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962771b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"ef1c3780\" -->\n",
    "La proportion des résultats positifs qui correspondent réellement à des sujets diabétiques (la précision) est de $67~\\%$.\n",
    "La proportion des sujets diabétiques détectés et qui le sont réellement (le rappel ou *recall*) est de $48~\\%$.\n",
    "\n",
    "On observe des F1-scores de $81~\\%$ pour les cas normaux et de $56~\\%$ pour les cas diabétiques.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ec376d01\" -->\n",
    "## Identification des variables les plus importantes pour diagnostiquer le diabète\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"0188acbb\" -->\n",
    "<p>&nbsp;</p>\n",
    "<div align=\"center\">\n",
    "    <img src= \"../images/inspector-with-magnifying-glass.jpeg\"  width=\"200\" />\n",
    "    <div>\n",
    "    <font size=\"0.5\">Image Source: http://clipart-library.com/clipart/1416328.htm</font>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"eb1eb36d\" -->\n",
    "> À noter que cette section est similaire à celle dans le module montrant un exemple de régression par forêt aléatoire. Toutefois,\n",
    "nous allons la revisiter, car les concepts qui y sont expliqués sont très utiles dans la pratique.\n",
    "\n",
    "Les variables $x_{i}$ les plus importantes sont les plus utilisées pour prendre des décisions à travers les arbres décisionnels constituant la forêt.\n",
    "\n",
    "L'importance de chaque variable correspond au nombre de fois qu'elle est utilisée dans la forêt aléatoire pour prendre une décision. Elle prend une valeur entre 0 et 1, où 0 indique qu'elle n'est jamais utilisée, et où 1 indique qu'elle est la seule utilisée parmi toutes. Dans ce dernier cas, la variable permet de prédire parfaitement la réponse.\n",
    "La somme des importances sur l'ensemble des variables vaut 1.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"dcc5fb85\" -->\n",
    "#### Calcul de l'importance de chaque variable\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d200e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(clf.feature_importances_)\n",
    "\n",
    "# Le nom de chaque variable est associé à son importance\n",
    "feature_importances = [\n",
    "    (feature, round(importance, 2))\n",
    "    for feature, importance in zip(feature_list, importances)\n",
    "]\n",
    "\n",
    "# Ordonnancement des valeurs d'importance en ordre décroissant\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c71520",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3a4a6006\" -->\n",
    "### Affichage du diagrame d'importance, ou du spectre d'importance, des variables du jeu de données\n",
    "\n",
    "On veut déterminer lesquelles sont les plus importantes et combien il y en a.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c639bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "var = list(range(len(importances)))\n",
    "plt.bar(var, np.array(importances)[indices.astype(int)], orientation='vertical')\n",
    "plt.xticks(var, np.array(feature_list)[indices.astype(int)], rotation='vertical')\n",
    "plt.ylabel('Importance', fontsize=16)\n",
    "plt.xlabel('Variable', fontsize=16)\n",
    "plt.title('Importance des variables', fontsize=16);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee13f0",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"b934ad71\" -->\n",
    "On remarque qu'il n'y a pas de séparation franche entre les variables. Toutefois, il semble y avoir un léger 'coude'\n",
    "dans la distribution à la quatrième variable. Ainsi, les quatre premières variables semblent être les plus\n",
    "importantes, soit en ordre décroissant:\n",
    "\n",
    "\n",
    "- le taux de glucose,\n",
    "- l'indice de masse corporelle (BMI),\n",
    "- l'âge,\n",
    "- le taux d'insuline.\n",
    "\n",
    "\n",
    "Notez bien que ces résultats ne sont valides que **pour ce  jeu de données** et pour le type de prétraitement utilisé. En effet, l'ordre précis des variables indicatrices peut légèrement changer en fonction du type de prétraitement ou du classificateur utilisés.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ea1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
