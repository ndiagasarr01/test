{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e61347",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .md\n",
    "      format_name: markdown\n",
    "      format_version: '1.3'\n",
    "      jupytext_version: 1.16.0\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    language: python\n",
    "    name: python3\n",
    "---\n",
    "\n",
    "<!-- #region id=\"9feccd08\" -->\n",
    "# Table des matières\n",
    "1. [Génération des données](#Génération-des-données)\n",
    "1. [Entraînement du modèle de régression](#Entraînement-du-modèle-de-régression)\n",
    "1. [Calcul de la métrique $R^2$ pour les données d'entraînement et de test](#Calcul-de-la-métrique-$R^2$-pour-les-données-d'entraînement-et-de-test)\n",
    "1. [Affichage des résultats](#Affichage-des-résultats)\n",
    "\n",
    "# Attention!\n",
    "Ne lancez pas l'exécution automatique du notebook en entier en cliquant sur le bouton **Tout exécuter**. L'exécution serait interrompue, car certaines cellules exigent une entrée de votre part!\n",
    "\n",
    "Il faut simplement exécuter le notebook, une cellule à la fois, et entrer quelques lignes de code lorsque demandées. Il est inutile de sauter ces cellules pour aller aux suivantes car celles-ci ont justement besoin de votre input!\n",
    "\n",
    "Importons d'abord les librairies nécessaires.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# semence pour le générateur de nombres pseudoaléatoires\n",
    "# permet d'assurer la reproductibilité des résultats\n",
    "seed = 42\n",
    "\n",
    "# initialisation du générateur à partir de la semence\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003087ca",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"72f195fe\" -->\n",
    "Dans cet exemple, nous allons voir un modèle de régression où la réponse $y$ dépend de deux variables $x_{1}$ et $x_{2}$ pour lesquelles on sait qu'il y a interaction entre elles. Dans cet exemple, les données sont simulées afin de\n",
    "simplifier l'analyse en plus de permettre au lecteur de modifier le nombre de données et le niveau de bruit\n",
    "dans celles-ci afin de voir les résultats sur l'analyse.\n",
    "\n",
    "On va montrer les différentes étapes de traitement de cet ensemble de données. C'est un exemple typique d'utilisation de\n",
    "la régression dans l'analyse d'un jeu de données expérimentales.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"9e4e9a93\" -->\n",
    "## Génération des données\n",
    "\n",
    "Nous allons générer un signal de la forme\n",
    "\n",
    "$$y = a_{0} + a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{1}x_{2}$$\n",
    "\n",
    "où les valeurs de $x_1$ et $x_2$ sont aléatoirement distribuées dans le plan $(x_1, x_2)$ afin de simuler un échantillonnage aléatoire.\n",
    "\n",
    "Nous allons ensuite additionner un bruit gaussien aux valeurs de $y$ afin de simuler des données expérimentales.\n",
    "\n",
    "Commençons par générer des positions aléatoires en $x_{1}$ et $x_{2}$ dans les intervalles $[0, 10]$ et $[0, 15]$ respectivement.\n",
    "\n",
    "> À noter que le nombre de points `npts` peut être modifié, dans ce qui suit, afin de voir son effet sur la qualité des régressions. Plus il y aura de points, meilleurs seront les résultats.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervalles des variables x1 et x2\n",
    "x1_min, x1_max = 0, 10\n",
    "x2_min, x2_max = 0, 15\n",
    "\n",
    "# taille de l'échantillon\n",
    "npts = 500\n",
    "\n",
    "# générer l'échantillon\n",
    "x1 = np.random.uniform(x1_min, x1_max, npts)\n",
    "x2 = np.random.uniform(x2_min, x2_max, npts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208eb45c",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"f91382bf\" -->\n",
    "Par la suite, générons le signal théorique $y = a_{0} + a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{1}x_{2}$.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramètres réels du modèle\n",
    "a = [0.10, 0.15, 0.20, 0.50]\n",
    "\n",
    "# valeur du signal théorique\n",
    "y = a[0] + a[1] * x1 + a[2] * x2 + a[3] * x1 * x2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c564d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"3a577e29\" -->\n",
    "Ajoutons maintenant le bruit gaussien afin de simuler des données expérimentales.\n",
    "\n",
    "\n",
    "> À noter que le niveau de bruit dans les données, qui est contrôlé par l'écart type du bruit $\\sigma$, peut être modifié afin de voir son effet sur la qualité des régressions. Les performances des régressions **diminuent** lorsque le niveau de bruit **augmente**.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# écart type du bruit gaussien\n",
    "sigma = 5\n",
    "\n",
    "# ajouter le bruit gaussien au signal\n",
    "y = y + np.random.normal(0.0, sigma, npts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0089c2e",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"aef40706\" -->\n",
    "Maintenant, effectuons la génération de la matrice des données $X$.\n",
    "\n",
    "On ne génère pas ici la première colonne remplie de 1 de la matrice $X$, car la classe\n",
    "[LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "de Scikit-learn (utilisée plus loin) la génère automatiquement.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947dccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([x1, x2, (x1 * x2)]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9aa8c2",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"5645903c\" -->\n",
    "Finalement, séparons les données en deux ensembles&puncsp;: les données d'entraînement ($80~\\%$) et les données de test ($20~\\%$).\n",
    "\n",
    "Les données d'entraînement vont servir à entraîner le modèle de régression, c'est-à-dire à estimer les valeurs des paramètres $a_0, a_1, a_2$ et $a_3$. Les données de test vont ensuite servir à mesurer les performances du modèle entraîné à prédire la réponse $y$ sans bruit.\n",
    "\n",
    "Dans la cellule ci-dessous, effectuez la séparation des données d'entraînement et des données de tests à l'aide de la fonction [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) en complétant l'énoncé avec les arguments de la fonction.\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparer les données en deux ensembles: entraînement et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef02b8",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"96925192\" -->\n",
    "## Entraînement du modèle de régression\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"92c43db1\" -->\n",
    "Débutons par l'estimation des valeurs des coefficients à partir des données d'entraînement. Pour cela, nous allons entraîner un modèle de régression linéaire ([`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)) de Scikit-learn avec les paramètres par défaut de la librairie.\n",
    "\n",
    "Dans la cellule ci-dessous, compléter les énoncés afin de créer un modèle et d'effectuer l'ajustement de ses paramètres avec les données d'entraînement (`X_train` et `y_train`).\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle linéaire\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# ajuster de ses paramètres en utilisant les données d'entraînement\n",
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd9750",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"e3fe7240\" -->\n",
    "On affiche maintenant la valeur des coefficients&puncsp;:\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3aa982",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valeurs des coefficients:\\n\")\n",
    "print(f\"\\ta0 vrai: {a[0]:0.2f} \\ta0 estimé: {reg.intercept_:0.2f}\")\n",
    "print(f\"\\ta1 vrai: {a[1]:0.2f} \\ta1 estimé: {reg.coef_[0]:0.2f}\")\n",
    "print(f\"\\ta2 vrai: {a[2]:0.2f} \\ta2 estimé: {reg.coef_[1]:0.2f}\")\n",
    "print(f\"\\ta3 vrai: {a[3]:0.2f} \\ta3 estimé: {reg.coef_[2]:0.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f8379",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"b0b97a8c\" -->\n",
    "Les coefficients vrais et mesurés sont parfois similaires et parfois assez différents. On observerait une meilleure concordance entre eux en réduisant le niveau de bruit $\\sigma$ dans les données expérimentales (jouez avec la valeur de la variable `sigma` pour voir). Il est à noter que la classe `LinearRegression` de Scikit-learn ne fournit pas les intervalles de confiance des coefficients.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"cff1cff7\" -->\n",
    "### Calcul de la métrique $R^2$ pour les données d'entraînement et de test\n",
    "\n",
    "Cette métrique est universellement utilisée pour mesurer les performances en régression. Elle est décrite dans le module sur les métriques de qualité en régression. En gros, elle mesure la fraction de l'information contenue dans les données qui est expliquée par le modèle. Une valeur de $R^2 =1$ implique que le modèle prédit exactement les valeurs de $y$. Une valeur de $R^2 =0$ implique que le modèle est incapable de prédire les valeurs de $y$. Elle prend des valeurs entre 0 et 1. Plus elle est près de 1, meilleure est l'adéquation entre le modèle et les données.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"06cf4069\" -->\n",
    "Dans la cellule ci-dessous, complétez les énoncés afin d'appliquer le modèle de régression sur les données d'entraînement et de test, et de calculer les scores $R^2$ pour les données d'entraînement et de test.\n",
    "\n",
    "Vous devez utiliser le modèle `reg` que nous avons entraîné afin de prédire le signal $y$ pour les données d'entraînement (`X_train`) et de tests (`X_test`).\n",
    "\n",
    "Ensuite, appelez la fonction [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html?highlight=r2_score#sklearn.metrics.r2_score)  de Scikit-learn pour calculer et afficher les scores $R^2$ correspondant.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer le modèle sur les données d'entraînement et de test\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "# calculer le score pour les données d'entraînement\n",
    "score = r2_score(y_train, y_train_pred)\n",
    "print(\"Valeur de R2 en entraînement:\", round(100*score, 1), \"%\")\n",
    "\n",
    "# calculer le score pour les données de test\n",
    "score = r2_score(y_test, y_test_pred)\n",
    "print(\"Valeur de R2 en test:\", round(100*score, 1), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7377d1",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"329fe91c\" -->\n",
    "On constate que les résultats sur les données d'entraînement sont supérieurs à ceux des données de test, ce qui est tout à fait normal. Les résultats sur les données de tests sont une meilleure estimation des performances réelles du modèle. Les résultats sur les données d'entraînement sont toujours surestimés par le fait que ce sont elles qui ont servi à estimer les paramètres du modèle.\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"b0827b42\" -->\n",
    "## Affichage des résultats\n",
    "<!-- #endregion -->\n",
    "\n",
    "<!-- #region id=\"ad2b837d\" -->\n",
    "Dans ce qui suit, nous allons voir dans quelle mesure le modèle entraîné reproduit bien la distribution des\n",
    "données d'entraînement et prédit bien les données de test.\n",
    "\n",
    "Nous débutons par générer une grille de valeurs $(u,v)$ couvrant la plage des valeurs de $x_{1}$ et $x_{2}$.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = np.meshgrid(\n",
    "    np.linspace(x1_min, x1_max, 30),\n",
    "    np.linspace(x2_min, x2_max, 30),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4c3db",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"49c69b18\" -->\n",
    "Par la suite, nous générons la matrice des données $X$ pour tous les points de la grille.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51724a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grille = np.vstack([u.ravel(), v.ravel(), (u * v).ravel()]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f432d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"e61090cc\" -->\n",
    "Nous effectuons ensuite la prédiction de la valeur de la réponse $y$ sur la grille.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = reg.predict(X_grille)\n",
    "w = w.reshape(u.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab476026",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"baac93d1\" -->\n",
    "Finalement, nous affichons les données d'entraînement $(x_{1},x_{2})$ et de la réponse $y = f(x_{1},x_{2})$.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax.plot_surface(\n",
    "    u, v, w, alpha=0.4, color=[1, 1, 0], shade=True, linewidth=0, antialiased=False\n",
    ")\n",
    "\n",
    "ax.scatter(x1, x2, y, c=\"k\", s=10)\n",
    "\n",
    "ax.set_xlabel(\"$x_{1}$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_{2}$\", rotation=0, fontsize=18)\n",
    "ax.set_zlabel(\"$y$\", fontsize=18)\n",
    "ax.set_title(\"Modèle linéaire avec interaction\", fontsize=18)\n",
    "\n",
    "ax.set_facecolor(\"#BBBBFF\")\n",
    "ax.grid(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e79d1d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"7eceabf9\" -->\n",
    "La figure ci-dessus montre que la surface $y=f(x_{1}, x_{2})$ reproduit bien la distribution des données d'entraînement.\n",
    "On remarque également l'interaction entre les valeurs de $x_{1}$ et $x_{2}$ qui produit la courbure de la surface.\n",
    "\n",
    "Comparons maintenant les réponses prédites et mesurées avec les données de test. La figure suivante montre la\n",
    "relation entre elles.\n",
    "<!-- #endregion -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliser les couleurs par défaut de seaborn\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# tracer le graphique\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(y_test_pred, y_test, \"o\", color=\"black\", markersize=5)\n",
    "ax.plot(y_test, y_test, color=\"yellow\", linewidth=2)\n",
    "ax.set_xlabel(\"$y_{test}$ prédite\", fontsize=18)\n",
    "ax.set_ylabel(\"$y_{test}$ vraie\", fontsize=18)\n",
    "ax.set_title(\"Valeurs de test\", fontsize=18)\n",
    "ax.set_facecolor(\"#BBBBFF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050957b",
   "metadata": {},
   "source": [
    "\n",
    "<!-- #region id=\"f311a23b\" -->\n",
    "Les données sont bien distribuées le long de la droite identité en jaune. Il y a une bonne adéquation entre les valeurs prédites et mesurées. C'est d'ailleurs ce qu'indiquait la valeur de $R_{test}^2$.\n",
    "\n",
    "Pour mieux saisir l'impact du bruit dans la qualité du modèle, essayez différentes valeurs pour la variable `sigma`. Si vous annulez le bruit, la modélisation sera parfaite. De même, expérimentez avec le nombre d'échantillons en modifiant la valeur de la variable `npts`. Jouez aussi avec la valeur de l'argument `test_size` pour la fonction `train_test_split`.\n",
    "<!-- #endregion -->\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
